<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 自定义 MapReduce 中的 OutputFormat · woodpile27</title><meta name="description" content="自定义 MapReduce 中的 OutputFormat - John Doe"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://woodpile27.cn/atom.xml" title="woodpile27"><meta name="generator" content="Hexo 5.0.2"><link rel="alternate" href="/atom.xml" title="woodpile27" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/woodpile27" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">自定义 MapReduce 中的 OutputFormat</h1><div class="post-info">Jun 5, 2021</div><div class="post-content"><p>在<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/OutputFormat.html">官方文档</a>中，OutputFormat 的功能被这样描述：<br>OutputFormat 描述了 MR job 的输出规范。</p>
<ol>
<li>验证作业的输出规范，例如检查输出目录是否已经存在。</li>
<li>提供 RecordWriter 的实现以用于写入作业的输出文件，输出文件存储在  FileSystem 中。</li>
</ol>
<p>OutputFormat 类中只有两个方法：<code>checkOutputSpecs</code> 和 <code>getRecordWriter</code>。分别用来检查输出和获取需要使用的 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/RecordWriter.html">RecordWriter</a>。<br>RecordWriter 从 reducer （或者 mapper）以 &lt;Key, Value&gt; 的形式获取输出数据，之后将这些数据写入输出文件。通过编写自己的 RecordWriter ，我们可以控制其写入的内容或者路径。RecordWriter 类也只有两个方法。<code>close</code>负责关闭它自己打开的文件流，<code>write</code>负责向输出文件中写入键值对。</p>
<h3 id="TextOutputFormat"><a href="#TextOutputFormat" class="headerlink" title="TextOutputFormat"></a>TextOutputFormat</h3><p>在自定义我们自己的 OutputFormat 之前，先来看看 hadoop 提供的 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextOutputFormat.html">TextOutputFormat</a>，它一般用来写入纯文本文件，也是 MR 中使用的默认 OutputFormat。TextOutputFormat 其实继承于 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/FileOutputFormat.html">FileOutputFormat</a>，FileOutputFormat 类提供了关于输出路径的一系列方法，接下来我们会用到其中的几个。<br>TextOutputFormat 并没有重写 <code>checkOutputSpecs</code> 方法，只定义了 <code>getRecordWriter</code>方法，还有一个自己使用的内部类 LineRecordWriter。</p>
<p>首先我们来看 <code>getRecordWriter</code>方法是如何实现的</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordWriter&lt;K, V&gt; <span class="title">getRecordWriter</span><span class="params">(FileSystem ignored,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                JobConf job,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                String name,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                Progressable progress)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> isCompressed = getCompressOutput(job);</span><br><span class="line">  String keyValueSeparator = job.get(<span class="string">&quot;mapreduce.output.textoutputformat.separator&quot;</span>, </span><br><span class="line">                                     <span class="string">&quot;\t&quot;</span>);  <span class="comment">// 获取key和value的分隔符</span></span><br><span class="line">  <span class="keyword">if</span> (!isCompressed) &#123;</span><br><span class="line">    Path file = FileOutputFormat.getTaskOutputPath(job, name); <span class="comment">// 创建任务的临时输出目录并返回</span></span><br><span class="line">    FileSystem fs = file.getFileSystem(job); <span class="comment">// 返回拥着这个路径的FileSystem</span></span><br><span class="line">    FSDataOutputStream fileOut = fs.create(file, progress); <span class="comment">// 在指定的路径创建一个FSDataOutputStream</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> LineRecordWriter&lt;K, V&gt;(fileOut, keyValueSeparator);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ......</span><br><span class="line">  &#125;   </span><br><span class="line">&#125;                                                                              </span><br></pre></td></tr></table></figure>
<p><code>getRecordWriter</code>首先得到了<code>isCompressed</code> 用以判断输出是否需要压缩，我们只需要关注更加简单的不需要压缩的逻辑即可。它先是获取了 <code>keyValueSeparator</code>，这个变量之后还要传给 LineRecordWriter 用来在输出文件中分隔 key 和 value。</p>
<p>之后它调用了 <code>getTaskOutputPath</code> 方法获取了任务的临时输出目录，这个目录一般在输出目录的 _temporary 下。<br>在 MR 任务的执行过程中，输出文件并不是直接写在提交者设置的输出目录中，而是先写入到临时目录下，在写入完成后再移动到输出目录。此外，一个 map 任务可能会有多个 mapper 在跑，他们的输出写入到临时目录下的不同目录中。当一个 mapper 成功后，其他的 mapper 将会被 kill，输出的文件也会被清理，这个过程是由 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/OutputCommitter.html">OutputCommitter</a> 控制的。</p>
<p>在网上的很多博客中，需要控制写入文件时，比如写入到不同的文件，都是调用了<code>getOutputPath</code>获取任务的输出路径后，直接写入。而如果一个任务有多个 mapper 同时在跑的时候，就会带来冲突。所以更正确的方法是先写入到临时路径，在写入成功后，MR 框架会帮我们自动移动到目标输出路径。（如果不对 OutputCommitter 做另外设置的话，最终的路径会跟想要设置的有所不同，下文中会有示例说明）</p>
<p>然后它调用了 <code>getFileSystem</code> 方法获取了拥着这个路径的 FileSystem，又调用了<code>create</code>在指定的路径上创建了一个 FSDataOutputStream 用来写入数。最后用 FSDataOutputStream 和 分隔符 新建了一个 LineRecordWriter 并返回。<br>接下来来看看 LineRecordWriter 的实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">protected static class LineRecordWriter&lt;K, V&gt;</span><br><span class="line">  implements RecordWriter&lt;K, V&gt; &#123;</span><br><span class="line">  private static final byte[] NEWLINE &#x3D;</span><br><span class="line">    &quot;\n&quot;.getBytes(StandardCharsets.UTF_8);</span><br><span class="line"></span><br><span class="line">  protected DataOutputStream out;</span><br><span class="line">  private final byte[] keyValueSeparator;</span><br><span class="line"></span><br><span class="line">  public LineRecordWriter(DataOutputStream out, String keyValueSeparator) &#123;</span><br><span class="line">    this.out &#x3D; out;</span><br><span class="line">    this.keyValueSeparator &#x3D;</span><br><span class="line">      keyValueSeparator.getBytes(StandardCharsets.UTF_8);</span><br><span class="line">  &#125;   </span><br><span class="line"></span><br><span class="line">  public LineRecordWriter(DataOutputStream out) &#123;</span><br><span class="line">    this(out, &quot;\t&quot;);</span><br><span class="line">  &#125;   </span><br><span class="line"></span><br><span class="line">  &#x2F;** </span><br><span class="line">   * Write the object to the byte stream, handling Text as a special</span><br><span class="line">   * case.</span><br><span class="line">   * @param o the object to print</span><br><span class="line">   * @throws IOException if the write throws, we pass it on</span><br><span class="line">   *&#x2F;</span><br><span class="line">  private void writeObject(Object o) throws IOException &#123;</span><br><span class="line">    if (o instanceof Text) &#123;</span><br><span class="line">      Text to &#x3D; (Text) o;</span><br><span class="line">      out.write(to.getBytes(), 0, to.getLength());</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      out.write(o.toString().getBytes(StandardCharsets.UTF_8));</span><br><span class="line">    &#125;   </span><br><span class="line">  &#125;   </span><br><span class="line"></span><br><span class="line">  public synchronized void write(K key, V value)</span><br><span class="line">    throws IOException &#123;</span><br><span class="line"></span><br><span class="line">    boolean nullKey &#x3D; key &#x3D;&#x3D; null || key instanceof NullWritable;</span><br><span class="line">    boolean nullValue &#x3D; value &#x3D;&#x3D; null || value instanceof NullWritable;</span><br><span class="line">    if (nullKey &amp;&amp; nullValue) &#123;</span><br><span class="line">      return;</span><br><span class="line">    &#125;   </span><br><span class="line">    if (!nullKey) &#123;</span><br><span class="line">      writeObject(key);</span><br><span class="line">    &#125;   </span><br><span class="line">    if (!(nullKey || nullValue)) &#123;</span><br><span class="line">      out.write(keyValueSeparator);</span><br><span class="line">    &#125;   </span><br><span class="line">    if (!nullValue) &#123;</span><br><span class="line">      writeObject(value);</span><br><span class="line">    &#125;   </span><br><span class="line">    out.write(NEWLINE);                                                                                                                                                                   </span><br><span class="line">  &#125;   </span><br><span class="line"></span><br><span class="line">  public synchronized void close(Reporter reporter) throws IOException &#123;</span><br><span class="line">    out.close();</span><br><span class="line">  &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到它的<code>write</code>方法其实非常简单，把 key、分隔符、value 和 \n 顺序写入。<code>close</code>方法则是把传入的 DataOutputStream  关闭。在 MR 框架的运行过程中，每个 mapper 会对应一个 RecordWriter，它会对 mapper 输出的每个 key-value 执行 <code>write</code> 操作。</p>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><p>例如我们需要处理的文件长这样，每行的 key 是一个 md5，value 是该 md5 对应的 base64 编码后的数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">35f1c5a1f891e055900bc8a37c56e6d6    MTIzNDU2</span><br><span class="line">0137d92b3d5df2dbb23b8ab6470b7a96    MTIzNDU2Nzg5MA&#x3D;&#x3D;</span><br><span class="line">28da0a34aa2c76a84eb0bfdfa492af89    YWJjZGVmZw&#x3D;&#x3D;</span><br></pre></td></tr></table></figure>
<p>我们想让每个 md5 对应的 base64 decode 后的数据都输出到一个单独的文件中，并且这个文件名中要有 md5 的值。</p>
<h4 id="TestOutputFormat"><a href="#TestOutputFormat" class="headerlink" title="TestOutputFormat"></a>TestOutputFormat</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestOutputFormat</span> <span class="keyword">extends</span> <span class="title">FileOutputFormat</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RecordWriter&lt;Text, Text&gt; <span class="title">getRecordWriter</span><span class="params">(FileSystem ignored,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                        JobConf job, String name,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                        Progressable progress)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Path file = FileOutputFormat.getTaskOutputPath(job, name);</span><br><span class="line">        String uniqueName = FileOutputFormat.getUniqueName(job, <span class="string">&quot;part&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> TestRecordWriter(file, job, uniqueName);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先通过<code>getTaskOutput</code>获取临时输出文件的路径，需要注意的是这里得到的是类似于 <code>xxxxxx/xxxxxx/part-00000</code>的一个路径，如果用这个路径直接与想要输出的文件名进行拼接，会在 output 目录下生成<code>part-00000</code>的目录，所以在 RecordWriter 中需要将这个路径名进行一些修改，去掉最后的<code>part-00000</code>。<br><code>getUniqueName</code>方法返回的 uniqueName 类似于<code>part-m-00001</code>，我们用它来区分不同 map 任务的输出文件。</p>
<h4 id="TestRecordWriter"><a href="#TestRecordWriter" class="headerlink" title="TestRecordWriter"></a>TestRecordWriter</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestRecordWriter</span> <span class="keyword">implements</span> <span class="title">RecordWriter</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">    </span><br><span class="line">    FileSystem fs;</span><br><span class="line">    String outputPath;</span><br><span class="line">    String uniqueName;</span><br><span class="line">    ArrayList&lt;FSDataOutputStream&gt; fileOuts = <span class="keyword">new</span> ArrayList&lt;FSDataOutputStream&gt;();</span><br><span class="line">    HashMap&lt;String, Integer&gt; hashCounter = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TestRecordWriter</span><span class="params">(Path file, JobConf job, String uniqueName)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.fs = file.getFileSystem(job);</span><br><span class="line">            String tempOutputPath = file.toString();</span><br><span class="line">            <span class="keyword">this</span>.outputPath = tempOutputPath.substring(<span class="number">0</span>, tempOutputPath.length() - <span class="number">11</span>);</span><br><span class="line">            <span class="keyword">this</span>.uniqueName = uniqueName;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;                             </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(Text key, Text value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String md5 = key.toString();</span><br><span class="line">        String base64Value = value.toString();</span><br><span class="line">        MessageDigest md = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            md = MessageDigest.getInstance(<span class="string">&quot;SHA-256&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchAlgorithmException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        md.update(md5.getBytes());</span><br><span class="line">        md.update(base64Value.getBytes());</span><br><span class="line">        <span class="keyword">byte</span>[] result = md.digest(); </span><br><span class="line">        BigInteger hash = <span class="keyword">new</span> BigInteger(<span class="number">1</span>, result);</span><br><span class="line">        String hashStr = hash.toString(<span class="number">16</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (hashCounter.containsKey(hashStr)) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            hashCounter.put(hashStr, <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Path testPath = <span class="keyword">new</span> Path(outputPath, md5 + <span class="string">&quot;_&quot;</span> + hashStr + <span class="string">&quot;_&quot;</span> + uniqueName);</span><br><span class="line">        FSDataOutputStream fileOut = <span class="keyword">null</span>;</span><br><span class="line">        fileOut = fs.create(testPath);</span><br><span class="line">        fileOuts.add(fileOut);</span><br><span class="line">        fileOut.write(Base64.decodeBase64(base64Value));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (FSDataOutputStream fileOut: fileOuts) &#123;</span><br><span class="line">            <span class="keyword">if</span> (fileOut != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    fileOut.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>首先对 tempOutputPath 进行了一些分割，目的是去掉其最后边的<code>/part-00000</code>。这里我们以 hash(md5+value) 对数据做了一个去重操作。可以看到输出的文件路径是 <code>Path(outputPath, md5 + &quot;_&quot; + hashStr + &quot;_&quot; + uniqueName)</code>，最后输出的文件名类似于<code>fffa244c21c0f21f62b9dc8b6d8e382a_de2a0e997648fdd240fe4012b518d07246e6b560114516c468f886fa6f010ba5_part-m-00001</code>。给文件名加上part-m-00001是为了防止不同的 mapper 输出同名文件。由于我们前边已经做了去重工作，而文件名又是包含 md5 和 hash 值的，所以同一个 mapper 输出的文件名是不会重复的，而如果可能出现重名的情况时，需要注意默认的<code>create</code>方法是不会覆盖的，<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/fs/FileSystem.html">FileSystem</a> 提供了<code>exists</code>，<code>create</code>等方法让我们使用，可以根据实际情况定制化开发。</p>
</div></article></div></main><footer><div class="paginator"><a href="/2021/07/03/effective_cpp_note_1_and_2/" class="prev">PREV</a><a href="/2021/04/25/use-hadoop-streaming-to-parse-pcap-files/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2021 <a href="http://woodpile27.cn">John Doe</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>