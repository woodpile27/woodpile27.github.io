<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 使用 Hadoop Streaming 解析 pcap 文件 · woodpile27</title><meta name="description" content="使用 Hadoop Streaming 解析 pcap 文件 - John Doe"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://woodpile27.cn/atom.xml" title="woodpile27"><meta name="generator" content="Hexo 5.0.2"><link rel="alternate" href="/atom.xml" title="woodpile27" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/woodpile27" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">使用 Hadoop Streaming 解析 pcap 文件</h1><div class="post-info">Apr 25, 2021</div><div class="post-content"><p>在最近的工作中遇到需要解析大量 pcap 文件的需求，部门里原来的做法是将储存在 HDFS 上的 pcap 文件下载到本地再进行处理，这样无疑会带来处理数量上的瓶颈，并且整个处理逻辑也比较复杂。通过为 Hadoop 编写解析 pcap 插件的方式使得可以直接使用 Hadoop 处理。</p>
<h3 id="hadoop-pcap"><a href="#hadoop-pcap" class="headerlink" title="hadoop-pcap"></a>hadoop-pcap</h3><p>github 上有一个 RIPE-NCC 的开源项目 <a target="_blank" rel="noopener" href="https://github.com/RIPE-NCC/hadoop-pcap">hadoop-pcap</a>，项目中的 <a target="_blank" rel="noopener" href="https://github.com/RIPE-NCC/hadoop-pcap/tree/master/hadoop-pcap-lib">hadoop-pcap-lib</a> 可以在 MapReduce 作业中使用来读取 pcap 文件。hadoop-pcap-lib 中还提供了各种协议的解析功能，如 dns、http 等，当然也可以根据自己的需求定制。在我们的需求中只需要将每个 pcap 文件中 packet 的 payload 按照顺序输出给同一个 mapper。下边我们来看一下项目中用到的关键类。</p>
<h4 id="PcapInputFormat"><a href="#PcapInputFormat" class="headerlink" title="PcapInputFormat"></a>PcapInputFormat</h4><p>hadoop steaming 中有一个 <code>-inputformat</code> 参数，来为 Hadoop 指定 InputFormatClass，这个类描述了 MR 的输入规范。<br>InputFormat 的作用：</p>
<ol>
<li>验证作业的输入格式</li>
<li>将输入文件拆分成 InputSplits，并将每个 InputSplit 分配给一个 mapper</li>
<li>提供 RecordReader 实现，用于从 InputSplit 读取输入（key-value）并提供给 mapper 处理</li>
</ol>
<p>用一句话来总结就是：InputFormat 定义如何将数据切割成分片和如何读取分片中的数据。这两个功能分别由 <code>getSplits()</code> 和 <code>RecordReader</code> 完成。</p>
<p>hadoop 中默认的 InputFormat 是 TextInputFormat，用于纯文本文件，也是我们一般所处理的文件，其输出的 value 是文件中的每一行， key 是每一行在文件中的位置。hadoop 中也提供了用于读取普通文件的 FileInputFormat、用于读取数据库的 DBInputFormat 等。<br>我们所要实现的 PcapInputFormat 继承自 FileInputFormat。FileInputFormat 是所有基于文件的 InputFormat 的基类，其提供了 getSplits 的通用实现，但一个 pcap 文件作为一个整体是不能拆分的，FileInputFormat 同样也提供了 <code>isSplitable</code> 方法防止文件被拆分，在 hadoop-pcap-lib 的 PcapInputFormat.java 中也可以看到重写了 <code>isSplitable</code> 方法让其 return false。这也正好符合我们让一个 mapper 处理一个 pcap 文件的需求。<br>PcapInputFormat.java 中还重写了 createRecordReader 方法，其返回一个自定义的 <code>RecordReader</code>：PcapRecordReader</p>
<h4 id="PcapRecordReader"><a href="#PcapRecordReader" class="headerlink" title="PcapRecordReader"></a>PcapRecordReader</h4><p>PcapRecordReader 其实并没有太关键的实现，也没有太复杂的逻辑。比较关键的几个方法是</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PcapReader pcapReader;</span><br><span class="line">   Iterator&lt;Packet&gt; pcapReaderIterator;</span><br><span class="line"><span class="keyword">long</span> packetCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (!pcapReaderIterator.hasNext())</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">       key.set(++packetCount);</span><br><span class="line">       value.set(pcapReaderIterator.next());</span><br><span class="line"></span><br><span class="line">       context.setStatus(<span class="string">&quot;Read &quot;</span> + getPos() + <span class="string">&quot; of &quot;</span> + end + <span class="string">&quot; bytes&quot;</span>);</span><br><span class="line">       context.progress();</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> ObjectWritable <span class="title">getCurrentValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> value;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> LongWritable <span class="title">getCurrentKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> key;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>nextKeyValue：读取下一个 key-value 键值对，可以看到 key 被设置成当前读取的 pcap 文件中 packetcount，value 被设置成 pcapReaderIterator.next()，pcapReaderIterator 是一个 packet 的迭代器，他来自 <code>PcapRecordReader</code> 的第一个参数 <code>PcapReader</code>类，其返回的其实是一个 <code>Packet</code>。</li>
<li>getCurrentValue：获取当前的 value</li>
<li>getCurrentKey：获取当前的 key</li>
</ul>
<p>mapper 在运行的过程中，首先会判断是否有下一个 key-value，如果有就传入当前的 key 和 value 到 map。</p>
<blockquote>
<p>另外需要注意的一点是不同版本的 Hadoop API 是有区别的，比如说在 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/RecordReader.html">RecordReader (Apache Hadoop Main 3.2.2 API)</a> 和 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/RecordReader.html">RecordReader (Apache Hadoop Main 3.3.0 API)</a> 中，RecordReader 类的方法就有所不同。目前的 hadoop-pcap-lib 跟 3.3.0 版本是一致的，但在实际环境中需要跟 hadoop 的版本保持一致。</p>
</blockquote>
<h4 id="Packet"><a href="#Packet" class="headerlink" title="Packet"></a>Packet</h4><p>在 PcapReader 之前先来说一下 Packet，它是一个 HashMap，它的 key 是 pcap 文件格式中 packet 的一些字段和 TCP/IP 协议中数据包的一些字段。其字段的值是在 PcapReader 中解析并设置的。在上面的 PcapRecordReader 中我们可以看到其输出的 key 就是一个 Packet，map 最终得到的值就是 Packet 中 toString 方法的输出。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Packet</span> <span class="keyword">extends</span> <span class="title">HashMap</span>&lt;<span class="title">String</span>, <span class="title">Object</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">8723206921174160146L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TIMESTAMP = <span class="string">&quot;ts&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TIMESTAMP_USEC = <span class="string">&quot;ts_usec&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TIMESTAMP_MICROS = <span class="string">&quot;ts_micros&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TTL = <span class="string">&quot;ttl&quot;</span>;</span><br><span class="line">    ......</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, Object&gt; entry : entrySet()) &#123;</span><br><span class="line">            sb.append(entry.getKey());</span><br><span class="line">            sb.append(<span class="string">&#x27;=&#x27;</span>);</span><br><span class="line">            sb.append(entry.getValue());</span><br><span class="line">            sb.append(<span class="string">&#x27;,&#x27;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (sb.length() &gt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> sb.substring(<span class="number">0</span>, sb.length() - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果需要自定义参数或者自定义输出，就改动 Packet 类的实现，比如在我们的需求中，就加入了 payload 字段。</p>
<h4 id="PcapReader"><a href="#PcapReader" class="headerlink" title="PcapReader"></a>PcapReader</h4><p>PcapReader 是 PcapInputFormat 中的 initPcapReader 方法创建的，其只有一个参数 is，类型是 DataInputStream，其实就是当前 PcapRecordReader 所处理的 pcap 文件流。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> PcapRecordReader <span class="title">initPcapRecordReader</span><span class="params">(Path path, <span class="keyword">long</span> start, <span class="keyword">long</span> length, Reporter reporter, Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    FileSystem fs = path.getFileSystem(conf);</span><br><span class="line">    FSDataInputStream baseStream = fs.open(path);</span><br><span class="line">    DataInputStream stream = baseStream;</span><br><span class="line">    CompressionCodecFactory compressionCodecs = <span class="keyword">new</span> CompressionCodecFactory(conf);</span><br><span class="line">       <span class="keyword">final</span> CompressionCodec codec = compressionCodecs.getCodec(path);</span><br><span class="line">       <span class="keyword">if</span> (codec != <span class="keyword">null</span>)</span><br><span class="line">           stream = <span class="keyword">new</span> DataInputStream(codec.createInputStream(stream));</span><br><span class="line"></span><br><span class="line">    PcapReader reader = initPcapReader(stream, conf);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> PcapRecordReader(reader, start, length, baseStream, stream, reporter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PcapReader 首先会使用 readBytes 方法读取 pcap 头，关于 pcap 文件格式这里就不过多介绍了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public PcapReader(DataInputStream is) throws IOException &#123;</span><br><span class="line">    this.is &#x3D; is;</span><br><span class="line">    iterator &#x3D; new PacketIterator();</span><br><span class="line"></span><br><span class="line">    pcapHeader &#x3D; new byte[HEADER_SIZE];</span><br><span class="line">    if (!readBytes(pcapHeader)) &#123;</span><br><span class="line">        &#x2F;&#x2F;</span><br><span class="line">        &#x2F;&#x2F; This special check for EOF is because we don&#39;t want</span><br><span class="line">        &#x2F;&#x2F; PcapReader to barf on an empty file.  This is the only</span><br><span class="line">        &#x2F;&#x2F; place we check caughtEOF.</span><br><span class="line">        &#x2F;&#x2F;</span><br><span class="line">        if (caughtEOF) &#123;</span><br><span class="line">            LOG.warn(&quot;Skipping empty file&quot;);</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        throw new IOException(&quot;Couldn&#39;t read PCAP header&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (!validateMagicNumber(pcapHeader))</span><br><span class="line">        throw new IOException(&quot;Not a PCAP file (Couldn&#39;t find magic number)&quot;);</span><br><span class="line"></span><br><span class="line">    snapLen &#x3D; PcapReaderUtil.convertInt(pcapHeader, PCAP_HEADER_SNAPLEN_OFFSET, reverseHeaderByteOrder);</span><br><span class="line"></span><br><span class="line">    long linkTypeVal &#x3D; PcapReaderUtil.convertInt(pcapHeader, PCAP_HEADER_LINKTYPE_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    if ((linkType &#x3D; getLinkType(linkTypeVal)) &#x3D;&#x3D; null)</span><br><span class="line">        throw new IOException(&quot;Unsupported link type: &quot; + linkTypeVal);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这部分就是 PcapRecordReader 直接调用的部分，PcapReader 本身是一个 Iterable 接口，它的 iterator 方法返回一个 Iterator 对象，可以使用for each 循环进行遍历，而 fetchNext 方法调用的是 PcapReader 的 nextPacket 方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">PacketIterator</span> <span class="keyword">implements</span> <span class="title">Iterator</span>&lt;<span class="title">Packet</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Packet next;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">fetchNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (next == <span class="keyword">null</span>)</span><br><span class="line">            next = nextPacket();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        fetchNext();</span><br><span class="line">        <span class="keyword">if</span> (next != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">int</span> remainingFlows = flows.size();</span><br><span class="line">        <span class="keyword">if</span> (remainingFlows &gt; <span class="number">0</span>)</span><br><span class="line">            LOG.warn(<span class="string">&quot;Still &quot;</span> + remainingFlows + <span class="string">&quot; flows queued. Missing packets to finish assembly?&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Packet <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        fetchNext();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> next;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            next = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Not supported</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>nextPacket 方法首先尝试读取一个 pcapPacketHeader ，即 pcap 中的 Packet Header 部分，接着创建一个 createPacket 对象，然后向其中写入 Packet Header 的一些字段，之后根据 Packet Header 中的 CAP_LEN 读取 Packet Data 部分，接着读取数据包的一些参数。<br>如果需要自定义输出，在这里也需要做出修改，在我们的需求中，写入 Packet 的 Payload 就可以直接返回了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Packet <span class="title">nextPacket</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    pcapPacketHeader = <span class="keyword">new</span> <span class="keyword">byte</span>[PACKET_HEADER_SIZE];</span><br><span class="line">    <span class="keyword">if</span> (!readBytes(pcapPacketHeader))</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    Packet packet = createPacket();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> packetTimestamp = PcapReaderUtil.convertInt(pcapPacketHeader, TIMESTAMP_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    packet.put(Packet.TIMESTAMP, packetTimestamp);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> packetTimestampMicros = PcapReaderUtil.convertInt(pcapPacketHeader, TIMESTAMP_MICROS_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    packet.put(Packet.TIMESTAMP_MICROS, packetTimestampMicros);</span><br><span class="line"></span><br><span class="line">       BigDecimal packetTimestampUsec = <span class="keyword">new</span> BigDecimal(packetTimestamp + packetTimestampMicros / <span class="number">1000000.0</span>, tsUsecMc);</span><br><span class="line">       packet.put(Packet.TIMESTAMP_USEC, packetTimestampUsec.doubleValue());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> packetSize = PcapReaderUtil.convertInt(pcapPacketHeader, CAP_LEN_OFFSET, reverseHeaderByteOrder);</span><br><span class="line">    packetData = <span class="keyword">new</span> <span class="keyword">byte</span>[(<span class="keyword">int</span>)packetSize];</span><br><span class="line">    <span class="keyword">if</span> (!readBytes(packetData))</span><br><span class="line">        <span class="keyword">return</span> packet;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ipStart = findIPStart(packetData);</span><br><span class="line">    ......</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure>

<h3 id="使用-hadoop-pcap"><a href="#使用-hadoop-pcap" class="headerlink" title="使用 hadoop-pcap"></a>使用 hadoop-pcap</h3><p>在了解了 hadoop-pcap 的基本原理后，我们可以定制自己的 pcap 解析程序，当然也可以使用其提供的一些功能。下面介绍一下如何使用已经定制好的 hadoop-pcap。</p>
<h4 id="编译-amp-打包"><a href="#编译-amp-打包" class="headerlink" title="编译&amp;打包"></a>编译&amp;打包</h4><p>为了简便，我把改写过的几个 java 文件放在了同一个文件夹里，项目结构如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── lib</span><br><span class="line">│   ├── apache-httpcomponents-httpclient.jar</span><br><span class="line">│   ├── commons-codec-1.9.jar</span><br><span class="line">│   ├── commons-lang3-3.3.2.jar</span><br><span class="line">│   ├── commons-logging-1.1.1.jar</span><br><span class="line">│   ├── commons-net-3.0.1.jar</span><br><span class="line">│   ├── dnsjava-2.1.1.jar</span><br><span class="line">│   ├── guava-11.0.jar</span><br><span class="line">│   ├── hadoop-0.20.2.1U11-core.jar</span><br><span class="line">│   ├── hadoop-0.20.2-cdh3u4-core.jar</span><br><span class="line">│   └── httpcore-4.2.1.jar</span><br><span class="line">├── src</span><br><span class="line">│   └── com</span><br><span class="line">│       └── netlab</span><br><span class="line">│           └── botnet</span><br><span class="line">│               ├── CombinePcapInputFormat.java</span><br><span class="line">│               ├── CombinePcapRecordReader.java</span><br><span class="line">│               ├── Flow.java</span><br><span class="line">│               ├── Packet.java</span><br><span class="line">│               ├── PcapInputFormat.java</span><br><span class="line">│               ├── PcapReader.java</span><br><span class="line">│               ├── PcapReaderUtil.java</span><br><span class="line">│               └── PcapRecordReader.java</span><br><span class="line">└── target</span><br></pre></td></tr></table></figure>
<p>使用 javac 编译。因为公司的 hadoop 版本不是最新的，使用的是 1.7 的 jdk，需要在编译时使用 -source 和 -target 参数指定版本。-cp 参数指定 lib 目录里程序所依赖的 jar 包。-d 指定输出目录，编译的结果会存放到 target 目录里。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javac -<span class="built_in">source</span> 1.7 -target 1.7 -cp <span class="string">&quot;./lib/*&quot;</span> -d target ./src/com/netlab/botnet/*.java</span><br></pre></td></tr></table></figure>
<p>在 target 目录里新建 META-INF/MENIFEST.MF 并写入 <code>Main-Class: PcapInputFormat</code>，之后执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar -cvfm pcapinputformat.jar META-INF/MENIFEST.MF com/netlab/botnet/*.class</span><br></pre></td></tr></table></figure>

<h4 id="运行-Hadoop-Straming"><a href="#运行-Hadoop-Straming" class="headerlink" title="运行 Hadoop Straming"></a>运行 Hadoop Straming</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">streaming_path=/usr/bin/hadoop/software/hadoop/contrib/streaming/hadoop-streaming.jar</span><br><span class="line">HADOOP=/usr/bin/hadoop/software/hadoop/bin/hadoop</span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP</span> jar <span class="variable">$streaming_path</span> \</span><br><span class="line">        -libjars <span class="string">&quot;/home/hdp-netlab/chailinyuan/fdark-test/pcapinputformat.jar&quot;</span> \</span><br><span class="line">        -inputformat <span class="string">&quot;com.netlab.botnet.PcapInputFormat&quot;</span> \</span><br><span class="line">        ......</span><br></pre></td></tr></table></figure>
<p>-libjars 参数是打包好的 jar 的位置，-inputformat 参数是 PcapInputFormat 的 package 名。</p>
</div></article></div></main><footer><div class="paginator"><a href="/2020/12/28/kubernetes-note-2/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2021 <a href="http://woodpile27.cn">John Doe</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>